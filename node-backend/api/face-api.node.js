
/*
Face-API
homepage: <https://github.com/vladmandic/face-api>
author: <https://github.com/vladmandic>'
*/

var ln = Object.create, Ye = Object.defineProperty, hn = Object.getPrototypeOf, xn = Object.prototype.hasOwnProperty, bn = Object.getOwnPropertyNames, gn = Object.getOwnPropertyDescriptor; var Er = o => Ye(o, "__esModule", { value: !0 }); var xo = (o, t) => () => (t || (t = { exports: {} }, o(t.exports, t)), t.exports), Ge = (o, t) => { for (var e in t) Ye(o, e, { get: t[e], enumerable: !0 }) }, vn = (o, t, e) => { if (t && typeof t == "object" || typeof t == "function") for (let r of bn(t)) !xn.call(o, r) && r !== "default" && Ye(o, r, { get: () => t[r], enumerable: !(e = gn(t, r)) || e.enumerable }); return o }, b = o => vn(Er(Ye(o != null ? ln(hn(o)) : {}, "default", o && o.__esModule && "default" in o ? { get: () => o.default, enumerable: !0 } : { value: o, enumerable: !0 })), o); var g = xo(Mr => { var yn = Object.create, Cr = Object.defineProperty, Fn = Object.getPrototypeOf, Tn = Object.prototype.hasOwnProperty, Pn = Object.getOwnPropertyNames, wn = Object.getOwnPropertyDescriptor, bo = o => Cr(o, "__esModule", { value: !0 }), go = (o, t, e) => { if (t && typeof t == "object" || typeof t == "function") for (let r of Pn(t)) !Tn.call(o, r) && r !== "default" && Cr(o, r, { get: () => t[r], enumerable: !(e = wn(t, r)) || e.enumerable }); return o }, _n = o => go(bo(Cr(o != null ? yn(Fn(o)) : {}, "default", o && o.__esModule && "default" in o ? { get: () => o.default, enumerable: !0 } : { value: o, enumerable: !0 })), o); bo(Mr); go(Mr, _n(require("@tensorflow/tfjs-node"))) }); var Po = xo((Ln, To) => { Er(Ln); Ge(Ln, { isNodejs: () => kn }); function kn() { return typeof global == "object" && !0 && typeof To != "undefined" && typeof process != "undefined" && !!process.version } }); Er(exports); Ge(exports, { AgeGenderNet: () => pr, BoundingBox: () => re, Box: () => D, ComposableTask: () => tt, ComputeAllFaceDescriptorsTask: () => At, ComputeFaceDescriptorsTaskBase: () => vr, ComputeSingleFaceDescriptorTask: () => Wt, DetectAllFaceLandmarksTask: () => Fr, DetectAllFacesTask: () => He, DetectFaceLandmarksTaskBase: () => yr, DetectFacesTaskBase: () => Pr, DetectSingleFaceLandmarksTask: () => Tr, DetectSingleFaceTask: () => wr, Dimensions: () => A, FACE_EXPRESSION_LABELS: () => Zr, FaceDetection: () => M, FaceDetectionNet: () => qo, FaceExpressionNet: () => cr, FaceExpressions: () => It, FaceLandmark68Net: () => le, FaceLandmark68TinyNet: () => dr, FaceLandmarkNet: () => Ro, FaceLandmarks: () => V, FaceLandmarks5: () => yo, FaceLandmarks68: () => ne, FaceMatch: () => Ee, FaceMatcher: () => Dr, FaceRecognitionNet: () => xe, Gender: () => vt, LabeledBox: () => Me, LabeledFaceDescriptors: () => xt, NetInput: () => bt, NeuralNetwork: () => S, ObjectDetection: () => Dt, Point: () => x, PredictedBox: () => Fo, Rect: () => oe, SsdMobilenetv1: () => Xt, SsdMobilenetv1Options: () => Z, TinyFaceDetector: () => Fe, TinyFaceDetectorOptions: () => gr, TinyYolov2: () => ve, TinyYolov2Options: () => ft, allFaces: () => Da, allFacesSsdMobilenetv1: () => un, allFacesTinyYolov2: () => _a, awaitMediaLoaded: () => zr, bufferToImage: () => Vr, computeFaceDescriptor: () => da, createCanvas: () => Yt, createCanvasFromMedia: () => Ie, createFaceDetectionNet: () => na, createFaceRecognitionNet: () => Un, createSsdMobilenetv1: () => Jo, createTinyFaceDetector: () => Ea, createTinyYolov2: () => ia, detectAllFaces: () => _r, detectFaceLandmarks: () => pn, detectFaceLandmarksTiny: () => pa, detectLandmarks: () => Pa, detectSingleFace: () => wa, draw: () => eo, env: () => _, euclideanDistance: () => lo, extendWithAge: () => hr, extendWithFaceDescriptor: () => lr, extendWithFaceDetection: () => $t, extendWithFaceExpressions: () => mr, extendWithFaceLandmarks: () => fe, extendWithGender: () => xr, extractFaceTensors: () => se, extractFaces: () => ae, fetchImage: () => Bn, fetchJson: () => Jr, fetchNetWeights: () => Rn, fetchOrThrow: () => Gt, getContext2dOrThrow: () => O, getMediaDimensions: () => Ht, imageTensorToCanvas: () => Ur, imageToSquare: () => Xr, inverseSigmoid: () => Mn, iou: () => Sr, isMediaElement: () => qe, isMediaLoaded: () => Ne, isWithAge: () => Xn, isWithFaceDetection: () => pt, isWithFaceExpressions: () => Kr, isWithFaceLandmarks: () => Vt, isWithGender: () => Jn, loadAgeGenderModel: () => ya, loadFaceDetectionModel: () => Fa, loadFaceExpressionModel: () => va, loadFaceLandmarkModel: () => xa, loadFaceLandmarkTinyModel: () => ba, loadFaceRecognitionModel: () => ga, loadSsdMobilenetv1Model: () => dn, loadTinyFaceDetectorModel: () => la, loadTinyYolov2Model: () => ha, loadWeightMap: () => qr, locateFaces: () => Ta, matchDimensions: () => On, minBbox: () => Ar, nets: () => P, nonMaxSuppression: () => Wr, normalize: () => ot, padToSquare: () => Br, predictAgeAndGender: () => fa, recognizeFaceExpressions: () => ua, resizeResults: () => fn, resolveInput: () => jt, shuffleArray: () => En, sigmoid: () => De, ssdMobilenetv1: () => mn, tf: () => Ma, tinyFaceDetector: () => ca, tinyYolov2: () => ma, toNetInput: () => E, utils: () => Nr, validateConfig: () => io, version: () => Ia }); var Ma = b(g()); var eo = {}; Ge(eo, { AnchorPosition: () => dt, DrawBox: () => Xe, DrawBoxOptions: () => Gr, DrawFaceLandmarks: () => to, DrawFaceLandmarksOptions: () => Qr, DrawTextField: () => Mt, DrawTextFieldOptions: () => Ce, drawContour: () => lt, drawDetections: () => Wn, drawFaceExpressions: () => $n, drawFaceLandmarks: () => jn }); function lt(o, t, e = !1) { if (o.beginPath(), t.slice(1).forEach(({ x: r, y: n }, a) => { let s = t[a]; o.moveTo(s.x, s.y), o.lineTo(r, n) }), e) { let r = t[t.length - 1], n = t[0]; if (!r || !n) return; o.moveTo(r.x, r.y), o.lineTo(n.x, n.y) } o.stroke() } var Nr = {}; Ge(Nr, { computeReshapedDimensions: () => kr, getCenterPoint: () => Ot, isDimensions: () => Ve, isEven: () => ze, isFloat: () => Lr, isTensor: () => Bt, isTensor1D: () => Dn, isTensor2D: () => Ir, isTensor3D: () => ht, isTensor4D: () => z, isValidNumber: () => rt, isValidProbablitiy: () => ee, range: () => ct, round: () => Rt }); var vo = b(g()); var A = class { constructor(t, e) { if (!rt(t) || !rt(e)) throw new Error(`Dimensions.constructor - expected width and height to be valid numbers, instead have ${JSON.stringify({ width: t, height: e })}`); this._width = t, this._height = e } get width() { return this._width } get height() { return this._height } reverse() { return new A(1 / this.width, 1 / this.height) } }; function Bt(o, t) { return o instanceof vo.Tensor && o.shape.length === t } function Dn(o) { return Bt(o, 1) } function Ir(o) { return Bt(o, 2) } function ht(o) { return Bt(o, 3) } function z(o) { return Bt(o, 4) } function Lr(o) { return o % 1 != 0 } function ze(o) { return o % 2 == 0 } function Rt(o, t = 2) { let e = 10 ** t; return Math.floor(o * e) / e } function Ve(o) { return o && o.width && o.height } function kr({ width: o, height: t }, e) { let r = e / Math.max(t, o); return new A(Math.round(o * r), Math.round(t * r)) } function Ot(o) { return o.reduce((t, e) => t.add(e), new x(0, 0)).div(new x(o.length, o.length)) } function ct(o, t, e) { return Array(o).fill(0).map((r, n) => t + n * e) } function rt(o) { return !!o && o !== Infinity && o !== -Infinity && !Number.isNaN(o) || o === 0 } function ee(o) { return rt(o) && o >= 0 && o <= 1 } var x = class { constructor(t, e) { this._x = t, this._y = e } get x() { return this._x } get y() { return this._y } add(t) { return new x(this.x + t.x, this.y + t.y) } sub(t) { return new x(this.x - t.x, this.y - t.y) } mul(t) { return new x(this.x * t.x, this.y * t.y) } div(t) { return new x(this.x / t.x, this.y / t.y) } abs() { return new x(Math.abs(this.x), Math.abs(this.y)) } magnitude() { return Math.sqrt(this.x ** 2 + this.y ** 2) } floor() { return new x(Math.floor(this.x), Math.floor(this.y)) } }; var D = class { static isRect(t) { return !!t && [t.x, t.y, t.width, t.height].every(rt) } static assertIsValidBox(t, e, r = !1) { if (!D.isRect(t)) throw new Error(`${e} - invalid box: ${JSON.stringify(t)}, expected object with properties x, y, width, height`); if (!r && (t.width < 0 || t.height < 0)) throw new Error(`${e} - width (${t.width}) and height (${t.height}) must be positive numbers`) } constructor(t, e = !0) { let r = t || {}, n = [r.left, r.top, r.right, r.bottom].every(rt), a = [r.x, r.y, r.width, r.height].every(rt); if (!a && !n) throw new Error(`Box.constructor - expected box to be IBoundingBox | IRect, instead have ${JSON.stringify(r)}`); let [s, i, c, m] = a ? [r.x, r.y, r.width, r.height] : [r.left, r.top, r.right - r.left, r.bottom - r.top]; D.assertIsValidBox({ x: s, y: i, width: c, height: m }, "Box.constructor", e), this._x = s, this._y = i, this._width = c, this._height = m } get x() { return this._x } get y() { return this._y } get width() { return this._width } get height() { return this._height } get left() { return this.x } get top() { return this.y } get right() { return this.x + this.width } get bottom() { return this.y + this.height } get area() { return this.width * this.height } get topLeft() { return new x(this.left, this.top) } get topRight() { return new x(this.right, this.top) } get bottomLeft() { return new x(this.left, this.bottom) } get bottomRight() { return new x(this.right, this.bottom) } round() { let [t, e, r, n] = [this.x, this.y, this.width, this.height].map(a => Math.round(a)); return new D({ x: t, y: e, width: r, height: n }) } floor() { let [t, e, r, n] = [this.x, this.y, this.width, this.height].map(a => Math.floor(a)); return new D({ x: t, y: e, width: r, height: n }) } toSquare() { let { x: t, y: e, width: r, height: n } = this, a = Math.abs(r - n); return r < n && (t -= a / 2, r += a), n < r && (e -= a / 2, n += a), new D({ x: t, y: e, width: r, height: n }) } rescale(t) { let e = Ve(t) ? t.width : t, r = Ve(t) ? t.height : t; return new D({ x: this.x * e, y: this.y * r, width: this.width * e, height: this.height * r }) } pad(t, e) { let [r, n, a, s] = [this.x - t / 2, this.y - e / 2, this.width + t, this.height + e]; return new D({ x: r, y: n, width: a, height: s }) } clipAtImageBorders(t, e) { let { x: r, y: n, right: a, bottom: s } = this, i = Math.max(r, 0), c = Math.max(n, 0), m = a - i, p = s - c, d = Math.min(m, t - i), u = Math.min(p, e - c); return new D({ x: i, y: c, width: d, height: u }).floor() } shift(t, e) { let { width: r, height: n } = this, a = this.x + t, s = this.y + e; return new D({ x: a, y: s, width: r, height: n }) } padAtBorders(t, e) { let r = this.width + 1, n = this.height + 1, a = 1, s = 1, i = r, c = n, m = this.left, p = this.top, d = this.right, u = this.bottom; return d > e && (i = -d + e + r, d = e), u > t && (c = -u + t + n, u = t), m < 1 && (c = 2 - m, m = 1), p < 1 && (c = 2 - p, p = 1), { dy: s, edy: c, dx: a, edx: i, y: p, ey: u, x: m, ex: d, w: r, h: n } } calibrate(t) { return new D({ left: this.left + t.left * this.width, top: this.top + t.top * this.height, right: this.right + t.right * this.width, bottom: this.bottom + t.bottom * this.height }).toSquare().round() } }; var re = class extends D { constructor(t, e, r, n, a = !1) { super({ left: t, top: e, right: r, bottom: n }, a) } }; var Dt = class { constructor(t, e, r, n, a) { this._imageDims = new A(a.width, a.height), this._score = t, this._classScore = e, this._className = r, this._box = new D(n).rescale(this._imageDims) } get score() { return this._score } get classScore() { return this._classScore } get className() { return this._className } get box() { return this._box } get imageDims() { return this._imageDims } get imageWidth() { return this.imageDims.width } get imageHeight() { return this.imageDims.height } get relativeBox() { return new D(this._box).rescale(this.imageDims.reverse()) } forSize(t, e) { return new Dt(this.score, this.classScore, this.className, this.relativeBox, { width: t, height: e }) } }; var M = class extends Dt { constructor(t, e, r) { super(t, t, "", e, r) } forSize(t, e) { let { score: r, relativeBox: n, imageDims: a } = super.forSize(t, e); return new M(r, n, a) } }; function Sr(o, t, e = !0) { let r = Math.max(0, Math.min(o.right, t.right) - Math.max(o.left, t.left)), n = Math.max(0, Math.min(o.bottom, t.bottom) - Math.max(o.top, t.top)), a = r * n; return e ? a / (o.area + t.area - a) : a / Math.min(o.area, t.area) } function Ar(o) { let t = o.map(i => i.x), e = o.map(i => i.y), r = t.reduce((i, c) => c < i ? c : i, Infinity), n = e.reduce((i, c) => c < i ? c : i, Infinity), a = t.reduce((i, c) => i < c ? c : i, 0), s = e.reduce((i, c) => i < c ? c : i, 0); return new re(r, n, a, s) } function Wr(o, t, e, r = !0) { let n = t.map((s, i) => ({ score: s, boxIndex: i })).sort((s, i) => s.score - i.score).map(s => s.boxIndex), a = []; for (; n.length > 0;) { let s = n.pop(); a.push(s); let i = n, c = []; for (let m = 0; m < i.length; m++) { let p = i[m], d = o[s], u = o[p]; c.push(Sr(d, u, r)) } n = n.filter((m, p) => c[p] <= e) } return a } var mt = b(g()); function ot(o, t) { return mt.tidy(() => { let [e, r, n] = t, a = mt.fill([...o.shape.slice(0, 3), 1], e, "float32"), s = mt.fill([...o.shape.slice(0, 3), 1], r, "float32"), i = mt.fill([...o.shape.slice(0, 3), 1], n, "float32"), c = mt.concat([a, s, i], 3); return mt.sub(o, c) }) } var Et = b(g()); function Br(o, t = !1) { return Et.tidy(() => { let [e, r] = o.shape.slice(1); if (e === r) return o; let n = Math.abs(e - r), a = Math.round(n * (t ? .5 : 1)), s = e > r ? 2 : 1, i = u => { let f = o.shape.slice(); return f[s] = u, Et.fill(f, 0, "float32") }, c = i(a), m = n - c.shape[s], d = [t && m ? i(m) : null, o, c].filter(u => !!u).map(u => Et.cast(u, "float32")); return Et.concat(d, s) }) } function En(o) { let t = o.slice(); for (let e = t.length - 1; e > 0; e--) { let r = Math.floor(Math.random() * (e + 1)), n = t[e]; t[e] = t[r], t[r] = n } return t } function De(o) { return 1 / (1 + Math.exp(-o)) } function Mn(o) { return Math.log(o / (1 - o)) } var oe = class extends D { constructor(t, e, r, n, a = !1) { super({ x: t, y: e, width: r, height: n }, a) } }; var Cn = .5, Nn = .43, In = .45, V = class { constructor(t, e, r = new x(0, 0)) { let { width: n, height: a } = e; this._imgDims = new A(n, a), this._shift = r, this._positions = t.map(s => s.mul(new x(n, a)).add(r)) } get shift() { return new x(this._shift.x, this._shift.y) } get imageWidth() { return this._imgDims.width } get imageHeight() { return this._imgDims.height } get positions() { return this._positions } get relativePositions() { return this._positions.map(t => t.sub(this._shift).div(new x(this.imageWidth, this.imageHeight))) } forSize(t, e) { return new this.constructor(this.relativePositions, { width: t, height: e }) } shiftBy(t, e) { return new this.constructor(this.relativePositions, this._imgDims, new x(t, e)) } shiftByPoint(t) { return this.shiftBy(t.x, t.y) } align(t, e = {}) { if (t) { let a = t instanceof M ? t.box.floor() : new D(t); return this.shiftBy(a.x, a.y).align(null, e) } let { useDlibAlignment: r, minBoxPadding: n } = { useDlibAlignment: !1, minBoxPadding: .2, ...e }; return r ? this.alignDlib() : this.alignMinBbox(n) } alignDlib() { let t = this.getRefPointsForAlignment(), [e, r, n] = t, a = d => n.sub(d).magnitude(), s = (a(e) + a(r)) / 2, i = Math.floor(s / In), c = Ot(t), m = Math.floor(Math.max(0, c.x - Cn * i)), p = Math.floor(Math.max(0, c.y - Nn * i)); return new oe(m, p, Math.min(i, this.imageWidth + m), Math.min(i, this.imageHeight + p)) } alignMinBbox(t) { let e = Ar(this.positions); return e.pad(e.width * t, e.height * t) } getRefPointsForAlignment() { throw new Error("getRefPointsForAlignment not implemented by base class") } }; var yo = class extends V { getRefPointsForAlignment() { let t = this.positions; return [t[0], t[1], Ot([t[3], t[4]])] } }; var ne = class extends V { getJawOutline() { return this.positions.slice(0, 17) } getLeftEyeBrow() { return this.positions.slice(17, 22) } getRightEyeBrow() { return this.positions.slice(22, 27) } getNose() { return this.positions.slice(27, 36) } getLeftEye() { return this.positions.slice(36, 42) } getRightEye() { return this.positions.slice(42, 48) } getMouth() { return this.positions.slice(48, 68) } getRefPointsForAlignment() { return [this.getLeftEye(), this.getRightEye(), this.getMouth()].map(Ot) } }; var Ee = class { constructor(t, e) { this._label = t, this._distance = e } get label() { return this._label } get distance() { return this._distance } toString(t = !0) { return `${this.label}${t ? ` (${Rt(this.distance)})` : ""}` } }; var Me = class extends D { static assertIsValidLabeledBox(t, e) { if (D.assertIsValidBox(t, e), !rt(t.label)) throw new Error(`${e} - expected property label (${t.label}) to be a number`) } constructor(t, e) { super(t); this._label = e } get label() { return this._label } }; var xt = class { constructor(t, e) { if (typeof t != "string") throw new Error("LabeledFaceDescriptors - constructor expected label to be a string"); if (!Array.isArray(e) || e.some(r => !(r instanceof Float32Array))) throw new Error("LabeledFaceDescriptors - constructor expected descriptors to be an array of Float32Array"); this._label = t, this._descriptors = e } get label() { return this._label } get descriptors() { return this._descriptors } toJSON() { return { label: this.label, descriptors: this.descriptors.map(t => Array.from(t)) } } static fromJSON(t) { let e = t.descriptors.map(r => new Float32Array(r)); return new xt(t.label, e) } }; var Fo = class extends Me { static assertIsValidPredictedBox(t, e) { if (Me.assertIsValidLabeledBox(t, e), !ee(t.score) || !ee(t.classScore)) throw new Error(`${e} - expected properties score (${t.score}) and (${t.classScore}) to be a number between [0, 1]`) } constructor(t, e, r, n) { super(t, e); this._score = r, this._classScore = n } get score() { return this._score } get classScore() { return this._classScore } }; function pt(o) { return o.detection instanceof M } function $t(o, t) { return { ...o, ...{ detection: t } } } function Rr() { let o = window.fetch; if (!o) throw new Error("fetch - missing fetch implementation for browser environment"); return { Canvas: HTMLCanvasElement, CanvasRenderingContext2D, Image: HTMLImageElement, ImageData, Video: HTMLVideoElement, createCanvasElement: () => document.createElement("canvas"), createImageElement: () => document.createElement("img"), fetch: o, readFile: () => { throw new Error("readFile - filesystem not available for browser environment") } } } function Ue(o) { let t = ""; if (!o) try { o = require("fs") } catch (r) { t = r.toString() } return { readFile: o ? r => new Promise((n, a) => { o.readFile(r, (s, i) => s ? a(s) : n(i)) }) : () => { throw new Error(`readFile - failed to require fs in nodejs environment with error: ${t}`) } } } function Or() { let o = global.Canvas || global.HTMLCanvasElement, t = global.Image || global.HTMLImageElement, e = () => { if (o) return new o; throw new Error("createCanvasElement - missing Canvas implementation for nodejs environment") }, r = () => { if (t) return new t; throw new Error("createImageElement - missing Image implementation for nodejs environment") }, n = global.fetch, a = Ue(); return { Canvas: o || class { }, CanvasRenderingContext2D: global.CanvasRenderingContext2D || class { }, Image: t || class { }, ImageData: global.ImageData || class { }, Video: global.HTMLVideoElement || class { }, createCanvasElement: e, createImageElement: r, fetch: n, ...a } } function $r() { return typeof window == "object" && typeof document != "undefined" && typeof HTMLImageElement != "undefined" && typeof HTMLCanvasElement != "undefined" && typeof HTMLVideoElement != "undefined" && typeof ImageData != "undefined" && typeof CanvasRenderingContext2D != "undefined" } var jr = b(Po()), k; function Sn() { if (!k) throw new Error("getEnv - environment is not defined, check isNodejs() and isBrowser()"); return k } function Hr(o) { k = o } function Yr() { return $r() ? Hr(Rr()) : (0, jr.isNodejs)() ? Hr(Or()) : null } function An(o) { if (k || Yr(), !k) throw new Error("monkeyPatch - environment is not defined, check isNodejs() and isBrowser()"); let { Canvas: t = k.Canvas, Image: e = k.Image } = o; k.Canvas = t, k.Image = e, k.createCanvasElement = o.createCanvasElement || (() => new t), k.createImageElement = o.createImageElement || (() => new e), k.ImageData = o.ImageData || k.ImageData, k.Video = o.Video || k.Video, k.fetch = o.fetch || k.fetch, k.readFile = o.readFile || k.readFile } var _ = { getEnv: Sn, setEnv: Hr, initialize: Yr, createBrowserEnv: Rr, createFileSystem: Ue, createNodejsEnv: Or, monkeyPatch: An, isBrowser: $r, isNodejs: jr.isNodejs }; Yr(); function jt(o) { return !_.isNodejs() && typeof o == "string" ? document.getElementById(o) : o } function O(o) { let { Canvas: t, CanvasRenderingContext2D: e } = _.getEnv(); if (o instanceof e) return o; let r = jt(o); if (!(r instanceof t)) throw new Error("resolveContext2d - expected canvas to be of instance of Canvas"); let n = r.getContext("2d"); if (!n) throw new Error("resolveContext2d - canvas 2d context is null"); return n } var dt; (function (o) { o.TOP_LEFT = "TOP_LEFT", o.TOP_RIGHT = "TOP_RIGHT", o.BOTTOM_LEFT = "BOTTOM_LEFT", o.BOTTOM_RIGHT = "BOTTOM_RIGHT" })(dt || (dt = {})); var Ce = class { constructor(t = {}) { let { anchorPosition: e, backgroundColor: r, fontColor: n, fontSize: a, fontStyle: s, padding: i } = t; this.anchorPosition = e || dt.TOP_LEFT, this.backgroundColor = r || "rgba(0, 0, 0, 0.5)", this.fontColor = n || "rgba(255, 255, 255, 1)", this.fontSize = a || 14, this.fontStyle = s || "Georgia", this.padding = i || 4 } }, Mt = class { constructor(t, e, r = {}) { this.text = typeof t == "string" ? [t] : t instanceof Mt ? t.text : t, this.anchor = e, this.options = new Ce(r) } measureWidth(t) { let { padding: e } = this.options; return this.text.map(r => t.measureText(r).width).reduce((r, n) => r < n ? n : r, 0) + 2 * e } measureHeight() { let { fontSize: t, padding: e } = this.options; return this.text.length * t + 2 * e } getUpperLeft(t, e) { let { anchorPosition: r } = this.options, n = r === dt.BOTTOM_RIGHT || r === dt.TOP_RIGHT, a = r === dt.BOTTOM_LEFT || r === dt.BOTTOM_RIGHT, s = this.measureWidth(t), i = this.measureHeight(), c = n ? this.anchor.x - s : this.anchor.x, m = a ? this.anchor.y - i : this.anchor.y; if (e) { let { width: p, height: d } = e, u = Math.max(Math.min(c, p - s), 0), f = Math.max(Math.min(m, d - i), 0); return { x: u, y: f } } return { x: c, y: m } } draw(t) { let e = jt(t), r = O(e), { backgroundColor: n, fontColor: a, fontSize: s, fontStyle: i, padding: c } = this.options; r.font = `${s}px ${i}`; let m = this.measureWidth(r), p = this.measureHeight(); r.fillStyle = n; let d = this.getUpperLeft(r, e); r.fillRect(d.x, d.y, m, p), r.fillStyle = a, this.text.forEach((u, f) => { let v = c + d.x, w = c + d.y + (f + 1) * s; r.fillText(u, v, w) }) } }; var Gr = class { constructor(t = {}) { let { boxColor: e, lineWidth: r, label: n, drawLabelOptions: a } = t; this.boxColor = e || "rgba(0, 0, 255, 1)", this.lineWidth = r || 2, this.label = n; let s = { anchorPosition: dt.BOTTOM_LEFT, backgroundColor: this.boxColor }; this.drawLabelOptions = new Ce({ ...s, ...a }) } }, Xe = class { constructor(t, e = {}) { this.box = new D(t), this.options = new Gr(e) } draw(t) { let e = O(t), { boxColor: r, lineWidth: n } = this.options, { x: a, y: s, width: i, height: c } = this.box; e.strokeStyle = r, e.lineWidth = n, e.strokeRect(a, s, i, c); let { label: m } = this.options; m && new Mt([m], { x: a - n / 2, y: s }, this.options.drawLabelOptions).draw(t) } }; function Wn(o, t) { (Array.isArray(t) ? t : [t]).forEach(r => { let n = r instanceof M ? r.score : pt(r) ? r.detection.score : void 0, a = r instanceof M ? r.box : pt(r) ? r.detection.box : new D(r), s = n ? `${Rt(n)}` : void 0; new Xe(a, { label: s }).draw(o) }) } var ue = b(g()); function Ne(o) { let { Image: t, Video: e } = _.getEnv(); return o instanceof t && o.complete || o instanceof e && o.readyState >= 3 } function zr(o) { return new Promise((t, e) => { if (o instanceof _.getEnv().Canvas || Ne(o)) return t(null); function r(a) { !a.currentTarget || (a.currentTarget.removeEventListener("load", n), a.currentTarget.removeEventListener("error", r), e(a)) } function n(a) { !a.currentTarget || (a.currentTarget.removeEventListener("load", n), a.currentTarget.removeEventListener("error", r), t(a)) } o.addEventListener("load", n), o.addEventListener("error", r) }) } function Vr(o) { return new Promise((t, e) => { o instanceof Blob || e(new Error("bufferToImage - expected buf to be of type: Blob")); let r = new FileReader; r.onload = () => { typeof r.result != "string" && e(new Error("bufferToImage - expected reader.result to be a string, in onload")); let n = _.getEnv().createImageElement(); n.onload = () => t(n), n.onerror = e, n.src = r.result }, r.onerror = e, r.readAsDataURL(o) }) } function Ht(o) { let { Image: t, Video: e } = _.getEnv(); return o instanceof t ? new A(o.naturalWidth, o.naturalHeight) : o instanceof e ? new A(o.videoWidth, o.videoHeight) : new A(o.width, o.height) } function Yt({ width: o, height: t }) { let { createCanvasElement: e } = _.getEnv(), r = e(); return r.width = o, r.height = t, r } function Ie(o, t) { let { ImageData: e } = _.getEnv(); if (!(o instanceof e) && !Ne(o)) throw new Error("createCanvasFromMedia - media has not finished loading yet"); let { width: r, height: n } = t || Ht(o), a = Yt({ width: r, height: n }); return o instanceof e ? O(a).putImageData(o, 0, 0) : O(a).drawImage(o, 0, 0, r, n), a } var Je = b(g()); async function Ur(o, t) { let e = t || _.getEnv().createCanvasElement(), [r, n, a] = o.shape.slice(z(o) ? 1 : 0), s = Je.tidy(() => o.as3D(r, n, a).toInt()); return await Je.browser.toPixels(s, e), s.dispose(), e } function qe(o) { let { Image: t, Canvas: e, Video: r } = _.getEnv(); return o instanceof t || o instanceof e || o instanceof r } var J = b(g()); function Xr(o, t, e = !1) { let { Image: r, Canvas: n } = _.getEnv(); if (!(o instanceof r || o instanceof n)) throw new Error("imageToSquare - expected arg0 to be HTMLImageElement | HTMLCanvasElement"); if (t <= 0) return Yt({ width: 1, height: 1 }); let a = Ht(o), s = t / Math.max(a.height, a.width), i = s * a.width, c = s * a.height, m = Yt({ width: t, height: t }), p = o instanceof n ? o : Ie(o), d = Math.abs(i - c) / 2, u = e && i < c ? d : 0, f = e && c < i ? d : 0; return p.width > 0 && p.height > 0 && O(m).drawImage(p, u, f, i, c), m } var bt = class { constructor(t, e = !1) { this._imageTensors = []; this._canvases = []; this._treatAsBatchInput = !1; this._inputDimensions = []; if (!Array.isArray(t)) throw new Error(`NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have ${t}`); this._treatAsBatchInput = e, this._batchSize = t.length, t.forEach((r, n) => { if (ht(r)) { this._imageTensors[n] = r, this._inputDimensions[n] = r.shape; return } if (z(r)) { let s = r.shape[0]; if (s !== 1) throw new Error(`NetInput - tf.Tensor4D with batchSize ${s} passed, but not supported in input array`); this._imageTensors[n] = r, this._inputDimensions[n] = r.shape.slice(1); return } let a = r instanceof _.getEnv().Canvas ? r : Ie(r); this._canvases[n] = a, this._inputDimensions[n] = [a.height, a.width, 3] }) } get imageTensors() { return this._imageTensors } get canvases() { return this._canvases } get isBatchInput() { return this.batchSize > 1 || this._treatAsBatchInput } get batchSize() { return this._batchSize } get inputDimensions() { return this._inputDimensions } get inputSize() { return this._inputSize } get reshapedInputDimensions() { return ct(this.batchSize, 0, 1).map((t, e) => this.getReshapedInputDimensions(e)) } getInput(t) { return this.canvases[t] || this.imageTensors[t] } getInputDimensions(t) { return this._inputDimensions[t] } getInputHeight(t) { return this._inputDimensions[t][0] } getInputWidth(t) { return this._inputDimensions[t][1] } getReshapedInputDimensions(t) { if (typeof this.inputSize != "number") throw new Error("getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet"); let e = this.getInputWidth(t), r = this.getInputHeight(t); return kr({ width: e, height: r }, this.inputSize) } toBatchTensor(t, e = !0) { return this._inputSize = t, J.tidy(() => { let r = ct(this.batchSize, 0, 1).map(a => { let s = this.getInput(a); if (s instanceof J.Tensor) { let i = z(s) ? s : s.expandDims(); return i = Br(i, e), (i.shape[1] !== t || i.shape[2] !== t) && (i = J.image.resizeBilinear(i, [t, t])), i.as3D(t, t, 3) } if (s instanceof _.getEnv().Canvas) return J.browser.fromPixels(Xr(s, t, e)); throw new Error(`toBatchTensor - at batchIdx ${a}, expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have ${s}`) }); return J.stack(r.map(a => J.cast(a, "float32"))).as4D(this.batchSize, t, t, 3) }) } }; async function E(o) { if (o instanceof bt) return o; let t = Array.isArray(o) ? o : [o]; if (!t.length) throw new Error("toNetInput - empty array passed as input"); let e = n => Array.isArray(o) ? ` at input index ${n}:` : "", r = t.map(jt); return r.forEach((n, a) => { if (!qe(n) && !ht(n) && !z(n)) throw typeof t[a] == "string" ? new Error(`toNetInput -${e(a)} string passed, but could not resolve HTMLElement for element id ${t[a]}`) : new Error(`toNetInput -${e(a)} expected media to be of type HTMLImageElement | HTMLVideoElement | HTMLCanvasElement | tf.Tensor3D, or to be an element id`); if (z(n)) { let s = n.shape[0]; if (s !== 1) throw new Error(`toNetInput -${e(a)} tf.Tensor4D with batchSize ${s} passed, but not supported in input array`) } }), await Promise.all(r.map(n => qe(n) && zr(n))), new bt(r, Array.isArray(o)) } async function ae(o, t) { let { Canvas: e } = _.getEnv(), r = o; if (!(o instanceof e)) { let s = await E(o); if (s.batchSize > 1) throw new Error("extractFaces - batchSize > 1 not supported"); let i = s.getInput(0); r = i instanceof e ? i : await Ur(i) } let n = O(r); return t.map(s => s instanceof M ? s.forSize(r.width, r.height).box.floor() : s).map(s => s.clipAtImageBorders(r.width, r.height)).map(({ x: s, y: i, width: c, height: m }) => { let p = Yt({ width: c, height: m }); return c > 0 && m > 0 && O(p).putImageData(n.getImageData(s, i, c, m), 0, 0), p }) } var Ze = b(g()); async function se(o, t) { if (!ht(o) && !z(o)) throw new Error("extractFaceTensors - expected image tensor to be 3D or 4D"); if (z(o) && o.shape[0] > 1) throw new Error("extractFaceTensors - batchSize > 1 not supported"); return Ze.tidy(() => { let [e, r, n] = o.shape.slice(z(o) ? 1 : 0); return t.map(i => i instanceof M ? i.forSize(r, e).box : i).map(i => i.clipAtImageBorders(r, e)).map(({ x: i, y: c, width: m, height: p }) => Ze.slice3d(o.as3D(e, r, n), [c, i, 0], [p, m, n])) }) } async function Gt(o, t) { let { fetch: e } = _.getEnv(), r = await e(o, t); if (!(r.status < 400)) throw new Error(`failed to fetch: (${r.status}) ${r.statusText}, from url: ${r.url}`); return r } async function Bn(o) { let t = await Gt(o), e = await t.blob(); if (!e.type.startsWith("image/")) throw new Error(`fetchImage - expected blob type to be of type image/*, instead have: ${e.type}, for url: ${t.url}`); return Vr(e) } async function Jr(o) { return (await Gt(o)).json() } async function Rn(o) { return new Float32Array(await (await Gt(o)).arrayBuffer()) } var wo = b(g()); function Ke(o, t) { let e = `${t}-weights_manifest.json`; if (!o) return { modelBaseUri: "", manifestUri: e }; if (o === "/") return { modelBaseUri: "/", manifestUri: `/${e}` }; let r = o.startsWith("http://") ? "http://" : o.startsWith("https://") ? "https://" : ""; o = o.replace(r, ""); let n = o.split("/").filter(i => i), a = o.endsWith(".json") ? n[n.length - 1] : e, s = r + (o.endsWith(".json") ? n.slice(0, n.length - 1) : n).join("/"); return s = o.startsWith("/") ? `/${s}` : s, { modelBaseUri: s, manifestUri: s === "/" ? `/${a}` : `${s}/${a}` } } async function qr(o, t) { let { manifestUri: e, modelBaseUri: r } = Ke(o, t), n = await Jr(e); return wo.io.loadWeights(n, r) } function On(o, t, e = !1) { let { width: r, height: n } = e ? Ht(t) : t; return o.width = r, o.height = n, { width: r, height: n } } var Nt = b(g()); var gt = b(g()); var S = class { constructor(t) { this._params = void 0; this._paramMappings = []; this._name = t } get params() { return this._params } get paramMappings() { return this._paramMappings } get isLoaded() { return !!this.params } getParamFromPath(t) { let { obj: e, objProp: r } = this.traversePropertyPath(t); return e[r] } reassignParamFromPath(t, e) { let { obj: r, objProp: n } = this.traversePropertyPath(t); r[n].dispose(), r[n] = e } getParamList() { return this._paramMappings.map(({ paramPath: t }) => ({ path: t, tensor: this.getParamFromPath(t) })) } getTrainableParams() { return this.getParamList().filter(t => t.tensor instanceof gt.Variable) } getFrozenParams() { return this.getParamList().filter(t => !(t.tensor instanceof gt.Variable)) } variable() { this.getFrozenParams().forEach(({ path: t, tensor: e }) => { this.reassignParamFromPath(t, e.variable()) }) } freeze() { this.getTrainableParams().forEach(({ path: t, tensor: e }) => { let r = gt.tensor(e.dataSync()); e.dispose(), this.reassignParamFromPath(t, r) }) } dispose(t = !0) { this.getParamList().forEach(e => { if (t && e.tensor.isDisposed) throw new Error(`param tensor has already been disposed for path ${e.path}`); e.tensor.dispose() }), this._params = void 0 } serializeParams() { return new Float32Array(this.getParamList().map(({ tensor: t }) => Array.from(t.dataSync())).reduce((t, e) => t.concat(e))) } async load(t) { if (t instanceof Float32Array) { this.extractWeights(t); return } await this.loadFromUri(t) } async loadFromUri(t) { if (t && typeof t != "string") throw new Error(`${this._name}.loadFromUri - expected model uri`); let e = await qr(t, this.getDefaultModelName()); this.loadFromWeightMap(e) } async loadFromDisk(t) { if (t && typeof t != "string") throw new Error(`${this._name}.loadFromDisk - expected model file path`); let { readFile: e } = _.getEnv(), { manifestUri: r, modelBaseUri: n } = Ke(t, this.getDefaultModelName()), a = m => Promise.all(m.map(p => e(p).then(d => d.buffer))), s = gt.io.weightsLoaderFactory(a), i = JSON.parse((await e(r)).toString()), c = await s(i, n); this.loadFromWeightMap(c) } loadFromWeightMap(t) { let { paramMappings: e, params: r } = this.extractParamsFromWeightMap(t); this._paramMappings = e, this._params = r } extractWeights(t) { let { paramMappings: e, params: r } = this.extractParams(t); this._paramMappings = e, this._params = r } traversePropertyPath(t) { if (!this.params) throw new Error("traversePropertyPath - model has no loaded params"); let e = t.split("/").reduce((a, s) => { if (!a.nextObj.hasOwnProperty(s)) throw new Error(`traversePropertyPath - object does not have property ${s}, for path ${t}`); return { obj: a.nextObj, objProp: s, nextObj: a.nextObj[s] } }, { nextObj: this.params }), { obj: r, objProp: n } = e; if (!r || !n || !(r[n] instanceof gt.Tensor)) throw new Error(`traversePropertyPath - parameter is not a tensor, for path ${t}`); return { obj: r, objProp: n } } }; var C = b(g()); var ie = b(g()); function $(o, t, e) { return ie.tidy(() => { let r = ie.separableConv2d(o, t.depthwise_filter, t.pointwise_filter, e, "same"); return r = ie.add(r, t.bias), r }) } function Qe(o, t, e = !1) { return C.tidy(() => { let r = C.relu(e ? C.add(C.conv2d(o, t.conv0.filters, [2, 2], "same"), t.conv0.bias) : $(o, t.conv0, [2, 2])), n = $(r, t.conv1, [1, 1]), a = C.relu(C.add(r, n)), s = $(a, t.conv2, [1, 1]); return C.relu(C.add(r, C.add(n, s))) }) } function Le(o, t, e = !1, r = !0) { return C.tidy(() => { let n = C.relu(e ? C.add(C.conv2d(o, t.conv0.filters, r ? [2, 2] : [1, 1], "same"), t.conv0.bias) : $(o, t.conv0, r ? [2, 2] : [1, 1])), a = $(n, t.conv1, [1, 1]), s = C.relu(C.add(n, a)), i = $(s, t.conv2, [1, 1]), c = C.relu(C.add(n, C.add(a, i))), m = $(c, t.conv3, [1, 1]); return C.relu(C.add(n, C.add(a, C.add(i, m)))) }) } var Ct = b(g()); function zt(o, t, e = "same", r = !1) { return Ct.tidy(() => { let n = Ct.add(Ct.conv2d(o, t.filters, [1, 1], e), t.bias); return r ? Ct.relu(n) : n }) } function W(o, t) { Object.keys(o).forEach(e => { t.some(r => r.originalPath === e) || o[e].dispose() }) } var tr = b(g()); function ce(o, t) { return (e, r, n, a) => { let s = tr.tensor4d(o(e * r * n * n), [n, n, e, r]), i = tr.tensor1d(o(r)); return t.push({ paramPath: `${a}/filters` }, { paramPath: `${a}/bias` }), { filters: s, bias: i } } } var er = b(g()); function rr(o, t) { return (e, r, n) => { let a = er.tensor2d(o(e * r), [e, r]), s = er.tensor1d(o(r)); return t.push({ paramPath: `${n}/weights` }, { paramPath: `${n}/bias` }), { weights: a, bias: s } } } var ke = b(g()); var or = class { constructor(t, e, r) { this.depthwise_filter = t; this.pointwise_filter = e; this.bias = r } }; function me(o, t) { return (e, r, n) => { let a = ke.tensor4d(o(3 * 3 * e), [3, 3, e, 1]), s = ke.tensor4d(o(e * r), [1, 1, e, r]), i = ke.tensor1d(o(r)); return t.push({ paramPath: `${n}/depthwise_filter` }, { paramPath: `${n}/pointwise_filter` }, { paramPath: `${n}/bias` }), new or(a, s, i) } } function pe(o) { return t => { let e = o(`${t}/depthwise_filter`, 4), r = o(`${t}/pointwise_filter`, 4), n = o(`${t}/bias`, 1); return new or(e, r, n) } } function j(o, t) { return (e, r, n) => { let a = o[e]; if (!Bt(a, r)) throw new Error(`expected weightMap[${e}] to be a Tensor${r}D, instead have ${a}`); return t.push({ originalPath: e, paramPath: n || e }), a } } function B(o) { let t = o; function e(n) { let a = t.slice(0, n); return t = t.slice(n), a } function r() { return t } return { extractWeights: e, getRemainingWeights: r } } function nr(o, t) { let e = ce(o, t), r = me(o, t); function n(s, i, c, m = !1) { let p = m ? e(s, i, 3, `${c}/conv0`) : r(s, i, `${c}/conv0`), d = r(i, i, `${c}/conv1`), u = r(i, i, `${c}/conv2`); return { conv0: p, conv1: d, conv2: u } } function a(s, i, c, m = !1) { let { conv0: p, conv1: d, conv2: u } = n(s, i, c, m), f = r(i, i, `${c}/conv3`); return { conv0: p, conv1: d, conv2: u, conv3: f } } return { extractDenseBlock3Params: n, extractDenseBlock4Params: a } } function _o(o) { let t = [], { extractWeights: e, getRemainingWeights: r } = B(o), { extractDenseBlock4Params: n } = nr(e, t), a = n(3, 32, "dense0", !0), s = n(32, 64, "dense1"), i = n(64, 128, "dense2"), c = n(128, 256, "dense3"); if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`); return { paramMappings: t, params: { dense0: a, dense1: s, dense2: i, dense3: c } } } function ar(o) { return t => { let e = o(`${t}/filters`, 4), r = o(`${t}/bias`, 1); return { filters: e, bias: r } } } function sr(o, t) { let e = j(o, t), r = ar(e), n = pe(e); function a(i, c = !1) { let m = c ? r(`${i}/conv0`) : n(`${i}/conv0`), p = n(`${i}/conv1`), d = n(`${i}/conv2`); return { conv0: m, conv1: p, conv2: d } } function s(i, c = !1) { let m = c ? r(`${i}/conv0`) : n(`${i}/conv0`), p = n(`${i}/conv1`), d = n(`${i}/conv2`), u = n(`${i}/conv3`); return { conv0: m, conv1: p, conv2: d, conv3: u } } return { extractDenseBlock3Params: a, extractDenseBlock4Params: s } } function Do(o) { let t = [], { extractDenseBlock4Params: e } = sr(o, t), r = { dense0: e("dense0", !0), dense1: e("dense1"), dense2: e("dense2"), dense3: e("dense3") }; return W(o, t), { params: r, paramMappings: t } } var Se = class extends S { constructor() { super("FaceFeatureExtractor") } forwardInput(t) { let { params: e } = this; if (!e) throw new Error("FaceFeatureExtractor - load model before inference"); return Nt.tidy(() => { let r = Nt.cast(t.toBatchTensor(112, !0), "float32"), a = ot(r, [122.782, 117.001, 104.298]).div(Nt.scalar(255)), s = Le(a, e.dense0, !0); return s = Le(s, e.dense1), s = Le(s, e.dense2), s = Le(s, e.dense3), s = Nt.avgPool(s, [7, 7], [2, 2], "valid"), s }) } async forward(t) { return this.forwardInput(await E(t)) } getDefaultModelName() { return "face_feature_extractor_model" } extractParamsFromWeightMap(t) { return Do(t) } extractParams(t) { return _o(t) } }; var Co = b(g()); var de = b(g()); function Ae(o, t) { return de.tidy(() => de.add(de.matMul(o, t.weights), t.bias)) } function Eo(o, t, e) { let r = [], { extractWeights: n, getRemainingWeights: a } = B(o), i = rr(n, r)(t, e, "fc"); if (a().length !== 0) throw new Error(`weights remaing after extract: ${a().length}`); return { paramMappings: r, params: { fc: i } } } function Mo(o) { let t = [], e = j(o, t); function r(a) { let s = e(`${a}/weights`, 2), i = e(`${a}/bias`, 1); return { weights: s, bias: i } } let n = { fc: r("fc") }; return W(o, t), { params: n, paramMappings: t } } function ir(o) { let t = {}, e = {}; return Object.keys(o).forEach(r => { let n = r.startsWith("fc") ? e : t; n[r] = o[r] }), { featureExtractorMap: t, classifierMap: e } } var We = class extends S { constructor(t, e) { super(t); this._faceFeatureExtractor = e } get faceFeatureExtractor() { return this._faceFeatureExtractor } runNet(t) { let { params: e } = this; if (!e) throw new Error(`${this._name} - load model before inference`); return Co.tidy(() => { let r = t instanceof bt ? this.faceFeatureExtractor.forwardInput(t) : t; return Ae(r.as2D(r.shape[0], -1), e.fc) }) } dispose(t = !0) { this.faceFeatureExtractor.dispose(t), super.dispose(t) } loadClassifierParams(t) { let { params: e, paramMappings: r } = this.extractClassifierParams(t); this._params = e, this._paramMappings = r } extractClassifierParams(t) { return Eo(t, this.getClassifierChannelsIn(), this.getClassifierChannelsOut()) } extractParamsFromWeightMap(t) { let { featureExtractorMap: e, classifierMap: r } = ir(t); return this.faceFeatureExtractor.loadFromWeightMap(e), Mo(r) } extractParams(t) { let e = this.getClassifierChannelsIn(), r = this.getClassifierChannelsOut(), n = r * e + r, a = t.slice(0, t.length - n), s = t.slice(t.length - n); return this.faceFeatureExtractor.extractWeights(a), this.extractClassifierParams(s) } }; var Zr = ["neutral", "happy", "sad", "angry", "fearful", "disgusted", "surprised"], It = class { constructor(t) { if (t.length !== 7) throw new Error(`FaceExpressions.constructor - expected probabilities.length to be 7, have: ${t.length}`); Zr.forEach((e, r) => { this[e] = t[r] }) } asSortedArray() { return Zr.map(t => ({ expression: t, probability: this[t] })).sort((t, e) => e.probability - t.probability) } }; var cr = class extends We { constructor(t = new Se) { super("FaceExpressionNet", t) } forwardInput(t) { return ue.tidy(() => ue.softmax(this.runNet(t))) } async forward(t) { return this.forwardInput(await E(t)) } async predictExpressions(t) { let e = await E(t), r = await this.forwardInput(e), n = await Promise.all(ue.unstack(r).map(async s => { let i = await s.data(); return s.dispose(), i })); r.dispose(); let a = n.map(s => new It(s)); return e.isBatchInput ? a : a[0] } getDefaultModelName() { return "face_expression_model" } getClassifierChannelsIn() { return 256 } getClassifierChannelsOut() { return 7 } }; function Kr(o) { return o.expressions instanceof It } function mr(o, t) { return { ...o, ...{ expressions: t } } } function $n(o, t, e = .1, r) { (Array.isArray(t) ? t : [t]).forEach(a => { let s = a instanceof It ? a : Kr(a) ? a.expressions : void 0; if (!s) throw new Error("drawFaceExpressions - expected faceExpressions to be FaceExpressions | WithFaceExpressions<{}> or array thereof"); let c = s.asSortedArray().filter(d => d.probability > e), m = pt(a) ? a.detection.box.bottomLeft : r || new x(0, 0); new Mt(c.map(d => `${d.expression} (${Rt(d.probability)})`), m).draw(o) }) } function Vt(o) { return pt(o) && o.landmarks instanceof V && o.unshiftedLandmarks instanceof V && o.alignedRect instanceof M } function fe(o, t) { let { box: e } = o.detection, r = t.shiftBy(e.x, e.y), n = r.align(), { imageDims: a } = o.detection, s = new M(o.detection.score, n.rescale(a.reverse()), a); return { ...o, ...{ landmarks: r, unshiftedLandmarks: t, alignedRect: s } } } var Qr = class { constructor(t = {}) { let { drawLines: e = !0, drawPoints: r = !0, lineWidth: n, lineColor: a, pointSize: s, pointColor: i } = t; this.drawLines = e, this.drawPoints = r, this.lineWidth = n || 1, this.pointSize = s || 2, this.lineColor = a || "rgba(0, 255, 255, 1)", this.pointColor = i || "rgba(255, 0, 255, 1)" } }, to = class { constructor(t, e = {}) { this.faceLandmarks = t, this.options = new Qr(e) } draw(t) { let e = O(t), { drawLines: r, drawPoints: n, lineWidth: a, lineColor: s, pointSize: i, pointColor: c } = this.options; if (r && this.faceLandmarks instanceof ne && (e.strokeStyle = s, e.lineWidth = a, lt(e, this.faceLandmarks.getJawOutline()), lt(e, this.faceLandmarks.getLeftEyeBrow()), lt(e, this.faceLandmarks.getRightEyeBrow()), lt(e, this.faceLandmarks.getNose()), lt(e, this.faceLandmarks.getLeftEye(), !0), lt(e, this.faceLandmarks.getRightEye(), !0), lt(e, this.faceLandmarks.getMouth(), !0)), n) { e.strokeStyle = c, e.fillStyle = c; let m = p => { e.beginPath(), e.arc(p.x, p.y, i, 0, 2 * Math.PI), e.fill() }; this.faceLandmarks.positions.forEach(m) } } }; function jn(o, t) { (Array.isArray(t) ? t : [t]).forEach(r => { let n = r instanceof V ? r : Vt(r) ? r.landmarks : void 0; if (!n) throw new Error("drawFaceLandmarks - expected faceExpressions to be FaceLandmarks | WithFaceLandmarks<WithFaceDetection<{}>> or array thereof"); new to(n).draw(o) }) } var No = "0.30.3"; var ut = b(g()); var I = b(g()); function Hn(o, t) { let e = ce(o, t), r = me(o, t); function n(s, i, c) { let m = r(s, i, `${c}/separable_conv0`), p = r(i, i, `${c}/separable_conv1`), d = e(s, i, 1, `${c}/expansion_conv`); return { separable_conv0: m, separable_conv1: p, expansion_conv: d } } function a(s, i) { let c = r(s, s, `${i}/separable_conv0`), m = r(s, s, `${i}/separable_conv1`), p = r(s, s, `${i}/separable_conv2`); return { separable_conv0: c, separable_conv1: m, separable_conv2: p } } return { extractConvParams: e, extractSeparableConvParams: r, extractReductionBlockParams: n, extractMainBlockParams: a } } function Io(o, t) { let e = [], { extractWeights: r, getRemainingWeights: n } = B(o), { extractConvParams: a, extractSeparableConvParams: s, extractReductionBlockParams: i, extractMainBlockParams: c } = Hn(r, e), m = a(3, 32, 3, "entry_flow/conv_in"), p = i(32, 64, "entry_flow/reduction_block_0"), d = i(64, 128, "entry_flow/reduction_block_1"), u = { conv_in: m, reduction_block_0: p, reduction_block_1: d }, f = {}; ct(t, 0, 1).forEach(y => { f[`main_block_${y}`] = c(128, `middle_flow/main_block_${y}`) }); let v = i(128, 256, "exit_flow/reduction_block"), w = s(256, 512, "exit_flow/separable_conv"), h = { reduction_block: v, separable_conv: w }; if (n().length !== 0) throw new Error(`weights remaing after extract: ${n().length}`); return { paramMappings: e, params: { entry_flow: u, middle_flow: f, exit_flow: h } } } function Yn(o, t) { let e = j(o, t), r = ar(e), n = pe(e); function a(i) { let c = n(`${i}/separable_conv0`), m = n(`${i}/separable_conv1`), p = r(`${i}/expansion_conv`); return { separable_conv0: c, separable_conv1: m, expansion_conv: p } } function s(i) { let c = n(`${i}/separable_conv0`), m = n(`${i}/separable_conv1`), p = n(`${i}/separable_conv2`); return { separable_conv0: c, separable_conv1: m, separable_conv2: p } } return { extractConvParams: r, extractSeparableConvParams: n, extractReductionBlockParams: a, extractMainBlockParams: s } } function Lo(o, t) { let e = [], { extractConvParams: r, extractSeparableConvParams: n, extractReductionBlockParams: a, extractMainBlockParams: s } = Yn(o, e), i = r("entry_flow/conv_in"), c = a("entry_flow/reduction_block_0"), m = a("entry_flow/reduction_block_1"), p = { conv_in: i, reduction_block_0: c, reduction_block_1: m }, d = {}; ct(t, 0, 1).forEach(w => { d[`main_block_${w}`] = s(`middle_flow/main_block_${w}`) }); let u = a("exit_flow/reduction_block"), f = n("exit_flow/separable_conv"), v = { reduction_block: u, separable_conv: f }; return W(o, e), { params: { entry_flow: p, middle_flow: d, exit_flow: v }, paramMappings: e } } function ko(o, t, e) { return I.add(I.conv2d(o, t.filters, e, "same"), t.bias) } function ro(o, t, e = !0) { let r = e ? I.relu(o) : o; return r = $(r, t.separable_conv0, [1, 1]), r = $(I.relu(r), t.separable_conv1, [1, 1]), r = I.maxPool(r, [3, 3], [2, 2], "same"), r = I.add(r, ko(o, t.expansion_conv, [2, 2])), r } function Gn(o, t) { let e = $(I.relu(o), t.separable_conv0, [1, 1]); return e = $(I.relu(e), t.separable_conv1, [1, 1]), e = $(I.relu(e), t.separable_conv2, [1, 1]), e = I.add(e, o), e } var oo = class extends S { constructor(t) { super("TinyXception"); this._numMainBlocks = t } forwardInput(t) { let { params: e } = this; if (!e) throw new Error("TinyXception - load model before inference"); return I.tidy(() => { let r = I.cast(t.toBatchTensor(112, !0), "float32"), a = ot(r, [122.782, 117.001, 104.298]).div(I.scalar(256)), s = I.relu(ko(a, e.entry_flow.conv_in, [2, 2])); return s = ro(s, e.entry_flow.reduction_block_0, !1), s = ro(s, e.entry_flow.reduction_block_1), ct(this._numMainBlocks, 0, 1).forEach(i => { s = Gn(s, e.middle_flow[`main_block_${i}`]) }), s = ro(s, e.exit_flow.reduction_block), s = I.relu($(s, e.exit_flow.separable_conv, [1, 1])), s }) } async forward(t) { return this.forwardInput(await E(t)) } getDefaultModelName() { return "tiny_xception_model" } extractParamsFromWeightMap(t) { return Lo(t, this._numMainBlocks) } extractParams(t) { return Io(t, this._numMainBlocks) } }; function So(o) { let t = [], { extractWeights: e, getRemainingWeights: r } = B(o), n = rr(e, t), a = n(512, 1, "fc/age"), s = n(512, 2, "fc/gender"); if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`); return { paramMappings: t, params: { fc: { age: a, gender: s } } } } function Ao(o) { let t = [], e = j(o, t); function r(a) { let s = e(`${a}/weights`, 2), i = e(`${a}/bias`, 1); return { weights: s, bias: i } } let n = { fc: { age: r("fc/age"), gender: r("fc/gender") } }; return W(o, t), { params: n, paramMappings: t } } var vt; (function (o) { o.FEMALE = "female", o.MALE = "male" })(vt || (vt = {})); var pr = class extends S { constructor(t = new oo(2)) { super("AgeGenderNet"); this._faceFeatureExtractor = t } get faceFeatureExtractor() { return this._faceFeatureExtractor } runNet(t) { let { params: e } = this; if (!e) throw new Error(`${this._name} - load model before inference`); return ut.tidy(() => { let r = t instanceof bt ? this.faceFeatureExtractor.forwardInput(t) : t, n = ut.avgPool(r, [7, 7], [2, 2], "valid").as2D(r.shape[0], -1), a = Ae(n, e.fc.age).as1D(), s = Ae(n, e.fc.gender); return { age: a, gender: s } }) } forwardInput(t) { return ut.tidy(() => { let { age: e, gender: r } = this.runNet(t); return { age: e, gender: ut.softmax(r) } }) } async forward(t) { return this.forwardInput(await E(t)) } async predictAgeAndGender(t) { let e = await E(t), r = await this.forwardInput(e), n = ut.unstack(r.age), a = ut.unstack(r.gender), s = n.map((c, m) => ({ ageTensor: c, genderTensor: a[m] })), i = await Promise.all(s.map(async ({ ageTensor: c, genderTensor: m }) => { let p = (await c.data())[0], d = (await m.data())[0], u = d > .5, f = u ? vt.MALE : vt.FEMALE, v = u ? d : 1 - d; return c.dispose(), m.dispose(), { age: p, gender: f, genderProbability: v } })); return r.age.dispose(), r.gender.dispose(), e.isBatchInput ? i : i[0] } getDefaultModelName() { return "age_gender_model" } dispose(t = !0) { this.faceFeatureExtractor.dispose(t), super.dispose(t) } loadClassifierParams(t) { let { params: e, paramMappings: r } = this.extractClassifierParams(t); this._params = e, this._paramMappings = r } extractClassifierParams(t) { return So(t) } extractParamsFromWeightMap(t) { let { featureExtractorMap: e, classifierMap: r } = ir(t); return this.faceFeatureExtractor.loadFromWeightMap(e), Ao(r) } extractParams(t) { let e = 512 * 1 + 1 + (512 * 2 + 2), r = t.slice(0, t.length - e), n = t.slice(t.length - e); return this.faceFeatureExtractor.extractWeights(r), this.extractClassifierParams(n) } }; var H = b(g()); var Be = class extends We { postProcess(t, e, r) { let n = r.map(({ width: s, height: i }) => { let c = e / Math.max(i, s); return { width: s * c, height: i * c } }), a = n.length; return H.tidy(() => { let s = (d, u) => H.stack([H.fill([68], d, "float32"), H.fill([68], u, "float32")], 1).as2D(1, 136).as1D(), i = (d, u) => { let { width: f, height: v } = n[d]; return u(f, v) ? Math.abs(f - v) / 2 : 0 }, c = d => i(d, (u, f) => u < f), m = d => i(d, (u, f) => f < u); return t.mul(H.fill([a, 136], e, "float32")).sub(H.stack(Array.from(Array(a), (d, u) => s(c(u), m(u))))).div(H.stack(Array.from(Array(a), (d, u) => s(n[u].width, n[u].height)))) }) } forwardInput(t) { return H.tidy(() => { let e = this.runNet(t); return this.postProcess(e, t.inputSize, t.inputDimensions.map(([r, n]) => ({ height: r, width: n }))) }) } async forward(t) { return this.forwardInput(await E(t)) } async detectLandmarks(t) { let e = await E(t), r = H.tidy(() => H.unstack(this.forwardInput(e))), n = await Promise.all(r.map(async (a, s) => { let i = Array.from(await a.data()), c = i.filter((p, d) => ze(d)), m = i.filter((p, d) => !ze(d)); return new ne(Array(68).fill(0).map((p, d) => new x(c[d], m[d])), { height: e.getInputHeight(s), width: e.getInputWidth(s) }) })); return r.forEach(a => a.dispose()), e.isBatchInput ? n : n[0] } getClassifierChannelsOut() { return 136 } }; var le = class extends Be { constructor(t = new Se) { super("FaceLandmark68Net", t) } getDefaultModelName() { return "face_landmark_68_model" } getClassifierChannelsIn() { return 256 } }; var Lt = b(g()); function Wo(o) { let t = [], { extractDenseBlock3Params: e } = sr(o, t), r = { dense0: e("dense0", !0), dense1: e("dense1"), dense2: e("dense2") }; return W(o, t), { params: r, paramMappings: t } } function Bo(o) { let t = [], { extractWeights: e, getRemainingWeights: r } = B(o), { extractDenseBlock3Params: n } = nr(e, t), a = n(3, 32, "dense0", !0), s = n(32, 64, "dense1"), i = n(64, 128, "dense2"); if (r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`); return { paramMappings: t, params: { dense0: a, dense1: s, dense2: i } } } var no = class extends S { constructor() { super("TinyFaceFeatureExtractor") } forwardInput(t) { let { params: e } = this; if (!e) throw new Error("TinyFaceFeatureExtractor - load model before inference"); return Lt.tidy(() => { let r = Lt.cast(t.toBatchTensor(112, !0), "float32"), a = ot(r, [122.782, 117.001, 104.298]).div(Lt.scalar(255)), s = Qe(a, e.dense0, !0); return s = Qe(s, e.dense1), s = Qe(s, e.dense2), s = Lt.avgPool(s, [14, 14], [2, 2], "valid"), s }) } async forward(t) { return this.forwardInput(await E(t)) } getDefaultModelName() { return "face_feature_extractor_tiny_model" } extractParamsFromWeightMap(t) { return Wo(t) } extractParams(t) { return Bo(t) } }; var dr = class extends Be { constructor(t = new no) { super("FaceLandmark68TinyNet", t) } getDefaultModelName() { return "face_landmark_68_tiny_model" } getClassifierChannelsIn() { return 128 } }; var Ro = class extends le { }; var U = b(g()); var he = b(g()); var ur = b(g()); function Oo(o, t) { return ur.add(ur.mul(o, t.weights), t.biases) } function ao(o, t, e, r, n = "same") { let { filters: a, bias: s } = t.conv, i = he.conv2d(o, a, e, n); return i = he.add(i, s), i = Oo(i, t.scale), r ? he.relu(i) : i } function $o(o, t) { return ao(o, t, [1, 1], !0) } function so(o, t) { return ao(o, t, [1, 1], !1) } function fr(o, t) { return ao(o, t, [2, 2], !0, "valid") } var Y = b(g()); function zn(o, t) { function e(i, c, m) { let p = o(i), d = p.length / (c * m * m); if (Lr(d)) throw new Error(`depth has to be an integer: ${d}, weights.length: ${p.length}, numFilters: ${c}, filterSize: ${m}`); return Y.tidy(() => Y.transpose(Y.tensor4d(p, [c, d, m, m]), [2, 3, 1, 0])) } function r(i, c, m, p) { let d = e(i, c, m), u = Y.tensor1d(o(c)); return t.push({ paramPath: `${p}/filters` }, { paramPath: `${p}/bias` }), { filters: d, bias: u } } function n(i, c) { let m = Y.tensor1d(o(i)), p = Y.tensor1d(o(i)); return t.push({ paramPath: `${c}/weights` }, { paramPath: `${c}/biases` }), { weights: m, biases: p } } function a(i, c, m, p) { let d = r(i, c, m, `${p}/conv`), u = n(c, `${p}/scale`); return { conv: d, scale: u } } function s(i, c, m, p, d = !1) { let u = a((d ? .5 : 1) * i, c, m, `${p}/conv1`), f = a(i, c, m, `${p}/conv2`); return { conv1: u, conv2: f } } return { extractConvLayerParams: a, extractResidualLayerParams: s } } function jo(o) { let { extractWeights: t, getRemainingWeights: e } = B(o), r = [], { extractConvLayerParams: n, extractResidualLayerParams: a } = zn(t, r), s = n(4704, 32, 7, "conv32_down"), i = a(9216, 32, 3, "conv32_1"), c = a(9216, 32, 3, "conv32_2"), m = a(9216, 32, 3, "conv32_3"), p = a(36864, 64, 3, "conv64_down", !0), d = a(36864, 64, 3, "conv64_1"), u = a(36864, 64, 3, "conv64_2"), f = a(36864, 64, 3, "conv64_3"), v = a(147456, 128, 3, "conv128_down", !0), w = a(147456, 128, 3, "conv128_1"), h = a(147456, 128, 3, "conv128_2"), y = a(589824, 256, 3, "conv256_down", !0), T = a(589824, 256, 3, "conv256_1"), F = a(589824, 256, 3, "conv256_2"), L = a(589824, 256, 3, "conv256_down_out"), G = Y.tidy(() => Y.transpose(Y.tensor2d(t(256 * 128), [128, 256]), [1, 0])); if (r.push({ paramPath: "fc" }), e().length !== 0) throw new Error(`weights remaing after extract: ${e().length}`); return { params: { conv32_down: s, conv32_1: i, conv32_2: c, conv32_3: m, conv64_down: p, conv64_1: d, conv64_2: u, conv64_3: f, conv128_down: v, conv128_1: w, conv128_2: h, conv256_down: y, conv256_1: T, conv256_2: F, conv256_down_out: L, fc: G }, paramMappings: r } } function Vn(o, t) { let e = j(o, t); function r(s) { let i = e(`${s}/scale/weights`, 1), c = e(`${s}/scale/biases`, 1); return { weights: i, biases: c } } function n(s) { let i = e(`${s}/conv/filters`, 4), c = e(`${s}/conv/bias`, 1), m = r(s); return { conv: { filters: i, bias: c }, scale: m } } function a(s) { return { conv1: n(`${s}/conv1`), conv2: n(`${s}/conv2`) } } return { extractConvLayerParams: n, extractResidualLayerParams: a } } function Ho(o) { let t = [], { extractConvLayerParams: e, extractResidualLayerParams: r } = Vn(o, t), n = e("conv32_down"), a = r("conv32_1"), s = r("conv32_2"), i = r("conv32_3"), c = r("conv64_down"), m = r("conv64_1"), p = r("conv64_2"), d = r("conv64_3"), u = r("conv128_down"), f = r("conv128_1"), v = r("conv128_2"), w = r("conv256_down"), h = r("conv256_1"), y = r("conv256_2"), T = r("conv256_down_out"), { fc: F } = o; if (t.push({ originalPath: "fc", paramPath: "fc" }), !Ir(F)) throw new Error(`expected weightMap[fc] to be a Tensor2D, instead have ${F}`); let L = { conv32_down: n, conv32_1: a, conv32_2: s, conv32_3: i, conv64_down: c, conv64_1: m, conv64_2: p, conv64_3: d, conv128_down: u, conv128_1: f, conv128_2: v, conv256_down: w, conv256_1: h, conv256_2: y, conv256_down_out: T, fc: F }; return W(o, t), { params: L, paramMappings: t } } var R = b(g()); function nt(o, t) { let e = $o(o, t.conv1); return e = so(e, t.conv2), e = R.add(e, o), e = R.relu(e), e } function Re(o, t) { let e = fr(o, t.conv1); e = so(e, t.conv2); let r = R.avgPool(o, 2, 2, "valid"), n = R.zeros(r.shape), a = r.shape[3] !== e.shape[3]; if (r.shape[1] !== e.shape[1] || r.shape[2] !== e.shape[2]) { let i = [...e.shape]; i[1] = 1; let c = R.zeros(i); e = R.concat([e, c], 1); let m = [...e.shape]; m[2] = 1; let p = R.zeros(m); e = R.concat([e, p], 2) } return r = a ? R.concat([r, n], 3) : r, e = R.add(r, e), e = R.relu(e), e } var xe = class extends S { constructor() { super("FaceRecognitionNet") } forwardInput(t) { let { params: e } = this; if (!e) throw new Error("FaceRecognitionNet - load model before inference"); return U.tidy(() => { let r = U.cast(t.toBatchTensor(150, !0), "float32"), a = ot(r, [122.782, 117.001, 104.298]).div(U.scalar(256)), s = fr(a, e.conv32_down); s = U.maxPool(s, 3, 2, "valid"), s = nt(s, e.conv32_1), s = nt(s, e.conv32_2), s = nt(s, e.conv32_3), s = Re(s, e.conv64_down), s = nt(s, e.conv64_1), s = nt(s, e.conv64_2), s = nt(s, e.conv64_3), s = Re(s, e.conv128_down), s = nt(s, e.conv128_1), s = nt(s, e.conv128_2), s = Re(s, e.conv256_down), s = nt(s, e.conv256_1), s = nt(s, e.conv256_2), s = Re(s, e.conv256_down_out); let i = s.mean([1, 2]); return U.matMul(i, e.fc) }) } async forward(t) { return this.forwardInput(await E(t)) } async computeFaceDescriptor(t) { var a; if ((a = t == null ? void 0 : t.shape) == null ? void 0 : a.some(s => s <= 0)) return new Float32Array(128); let e = await E(t), r = U.tidy(() => U.unstack(this.forwardInput(e))), n = await Promise.all(r.map(s => s.data())); return r.forEach(s => s.dispose()), e.isBatchInput ? n : n[0] } getDefaultModelName() { return "face_recognition_model" } extractParamsFromWeightMap(t) { return Ho(t) } extractParams(t) { return jo(t) } }; function Un(o) { let t = new xe; return t.extractWeights(o), t } function lr(o, t) { return { ...o, ...{ descriptor: t } } } function Xn(o) { return typeof o.age == "number" } function hr(o, t) { return { ...o, ...{ age: t } } } function Jn(o) { return (o.gender === vt.MALE || o.gender === vt.FEMALE) && ee(o.genderProbability) } function xr(o, t, e) { return { ...o, ...{ gender: t, genderProbability: e } } } var st = b(g()); var at = b(g()); function qn(o, t) { function e(c, m) { let p = at.tensor4d(o(3 * 3 * c), [3, 3, c, 1]), d = at.tensor1d(o(c)), u = at.tensor1d(o(c)), f = at.tensor1d(o(c)), v = at.tensor1d(o(c)); return t.push({ paramPath: `${m}/filters` }, { paramPath: `${m}/batch_norm_scale` }, { paramPath: `${m}/batch_norm_offset` }, { paramPath: `${m}/batch_norm_mean` }, { paramPath: `${m}/batch_norm_variance` }), { filters: p, batch_norm_scale: d, batch_norm_offset: u, batch_norm_mean: f, batch_norm_variance: v } } function r(c, m, p, d, u) { let f = at.tensor4d(o(c * m * p * p), [p, p, c, m]), v = at.tensor1d(o(m)); return t.push({ paramPath: `${d}/filters` }, { paramPath: `${d}/${u ? "batch_norm_offset" : "bias"}` }), { filters: f, bias: v } } function n(c, m, p, d) { let { filters: u, bias: f } = r(c, m, p, d, !0); return { filters: u, batch_norm_offset: f } } function a(c, m, p) { let d = e(c, `${p}/depthwise_conv`), u = n(c, m, 1, `${p}/pointwise_conv`); return { depthwise_conv: d, pointwise_conv: u } } function s() { let c = n(3, 32, 3, "mobilenetv1/conv_0"), m = a(32, 64, "mobilenetv1/conv_1"), p = a(64, 128, "mobilenetv1/conv_2"), d = a(128, 128, "mobilenetv1/conv_3"), u = a(128, 256, "mobilenetv1/conv_4"), f = a(256, 256, "mobilenetv1/conv_5"), v = a(256, 512, "mobilenetv1/conv_6"), w = a(512, 512, "mobilenetv1/conv_7"), h = a(512, 512, "mobilenetv1/conv_8"), y = a(512, 512, "mobilenetv1/conv_9"), T = a(512, 512, "mobilenetv1/conv_10"), F = a(512, 512, "mobilenetv1/conv_11"), L = a(512, 1024, "mobilenetv1/conv_12"), G = a(1024, 1024, "mobilenetv1/conv_13"); return { conv_0: c, conv_1: m, conv_2: p, conv_3: d, conv_4: u, conv_5: f, conv_6: v, conv_7: w, conv_8: h, conv_9: y, conv_10: T, conv_11: F, conv_12: L, conv_13: G } } function i() { let c = n(1024, 256, 1, "prediction_layer/conv_0"), m = n(256, 512, 3, "prediction_layer/conv_1"), p = n(512, 128, 1, "prediction_layer/conv_2"), d = n(128, 256, 3, "prediction_layer/conv_3"), u = n(256, 128, 1, "prediction_layer/conv_4"), f = n(128, 256, 3, "prediction_layer/conv_5"), v = n(256, 64, 1, "prediction_layer/conv_6"), w = n(64, 128, 3, "prediction_layer/conv_7"), h = r(512, 12, 1, "prediction_layer/box_predictor_0/box_encoding_predictor"), y = r(512, 9, 1, "prediction_layer/box_predictor_0/class_predictor"), T = r(1024, 24, 1, "prediction_layer/box_predictor_1/box_encoding_predictor"), F = r(1024, 18, 1, "prediction_layer/box_predictor_1/class_predictor"), L = r(512, 24, 1, "prediction_layer/box_predictor_2/box_encoding_predictor"), G = r(512, 18, 1, "prediction_layer/box_predictor_2/class_predictor"), et = r(256, 24, 1, "prediction_layer/box_predictor_3/box_encoding_predictor"), it = r(256, 18, 1, "prediction_layer/box_predictor_3/class_predictor"), X = r(256, 24, 1, "prediction_layer/box_predictor_4/box_encoding_predictor"), Pt = r(256, 18, 1, "prediction_layer/box_predictor_4/class_predictor"), wt = r(128, 24, 1, "prediction_layer/box_predictor_5/box_encoding_predictor"), _t = r(128, 18, 1, "prediction_layer/box_predictor_5/class_predictor"); return { conv_0: c, conv_1: m, conv_2: p, conv_3: d, conv_4: u, conv_5: f, conv_6: v, conv_7: w, box_predictor_0: { box_encoding_predictor: h, class_predictor: y }, box_predictor_1: { box_encoding_predictor: T, class_predictor: F }, box_predictor_2: { box_encoding_predictor: L, class_predictor: G }, box_predictor_3: { box_encoding_predictor: et, class_predictor: it }, box_predictor_4: { box_encoding_predictor: X, class_predictor: Pt }, box_predictor_5: { box_encoding_predictor: wt, class_predictor: _t } } } return { extractMobilenetV1Params: s, extractPredictionLayerParams: i } } function Yo(o) { let t = [], { extractWeights: e, getRemainingWeights: r } = B(o), { extractMobilenetV1Params: n, extractPredictionLayerParams: a } = qn(e, t), s = n(), i = a(), m = { extra_dim: at.tensor3d(e(5118 * 4), [1, 5118, 4]) }; if (t.push({ paramPath: "output_layer/extra_dim" }), r().length !== 0) throw new Error(`weights remaing after extract: ${r().length}`); return { params: { mobilenetv1: s, prediction_layer: i, output_layer: m }, paramMappings: t } } function Zn(o, t) { let e = j(o, t); function r(m, p, d) { let u = e(`${m}/Conv2d_${p}_pointwise/weights`, 4, `${d}/filters`), f = e(`${m}/Conv2d_${p}_pointwise/convolution_bn_offset`, 1, `${d}/batch_norm_offset`); return { filters: u, batch_norm_offset: f } } function n(m) { let p = `mobilenetv1/conv_${m}`, d = `MobilenetV1/Conv2d_${m}_depthwise`, u = `${p}/depthwise_conv`, f = `${p}/pointwise_conv`, v = e(`${d}/depthwise_weights`, 4, `${u}/filters`), w = e(`${d}/BatchNorm/gamma`, 1, `${u}/batch_norm_scale`), h = e(`${d}/BatchNorm/beta`, 1, `${u}/batch_norm_offset`), y = e(`${d}/BatchNorm/moving_mean`, 1, `${u}/batch_norm_mean`), T = e(`${d}/BatchNorm/moving_variance`, 1, `${u}/batch_norm_variance`); return { depthwise_conv: { filters: v, batch_norm_scale: w, batch_norm_offset: h, batch_norm_mean: y, batch_norm_variance: T }, pointwise_conv: r("MobilenetV1", m, f) } } function a() { return { conv_0: r("MobilenetV1", 0, "mobilenetv1/conv_0"), conv_1: n(1), conv_2: n(2), conv_3: n(3), conv_4: n(4), conv_5: n(5), conv_6: n(6), conv_7: n(7), conv_8: n(8), conv_9: n(9), conv_10: n(10), conv_11: n(11), conv_12: n(12), conv_13: n(13) } } function s(m, p) { let d = e(`${m}/weights`, 4, `${p}/filters`), u = e(`${m}/biases`, 1, `${p}/bias`); return { filters: d, bias: u } } function i(m) { let p = s(`Prediction/BoxPredictor_${m}/BoxEncodingPredictor`, `prediction_layer/box_predictor_${m}/box_encoding_predictor`), d = s(`Prediction/BoxPredictor_${m}/ClassPredictor`, `prediction_layer/box_predictor_${m}/class_predictor`); return { box_encoding_predictor: p, class_predictor: d } } function c() { return { conv_0: r("Prediction", 0, "prediction_layer/conv_0"), conv_1: r("Prediction", 1, "prediction_layer/conv_1"), conv_2: r("Prediction", 2, "prediction_layer/conv_2"), conv_3: r("Prediction", 3, "prediction_layer/conv_3"), conv_4: r("Prediction", 4, "prediction_layer/conv_4"), conv_5: r("Prediction", 5, "prediction_layer/conv_5"), conv_6: r("Prediction", 6, "prediction_layer/conv_6"), conv_7: r("Prediction", 7, "prediction_layer/conv_7"), box_predictor_0: i(0), box_predictor_1: i(1), box_predictor_2: i(2), box_predictor_3: i(3), box_predictor_4: i(4), box_predictor_5: i(5) } } return { extractMobilenetV1Params: a, extractPredictionLayerParams: c } } function Go(o) { let t = [], { extractMobilenetV1Params: e, extractPredictionLayerParams: r } = Zn(o, t), n = o["Output/extra_dim"]; if (t.push({ originalPath: "Output/extra_dim", paramPath: "output_layer/extra_dim" }), !ht(n)) throw new Error(`expected weightMap['Output/extra_dim'] to be a Tensor3D, instead have ${n}`); let a = { mobilenetv1: e(), prediction_layer: r(), output_layer: { extra_dim: n } }; return W(o, t), { params: a, paramMappings: t } } var yt = b(g()); var kt = b(g()); function q(o, t, e) { return kt.tidy(() => { let r = kt.conv2d(o, t.filters, e, "same"); return r = kt.add(r, t.batch_norm_offset), kt.clipByValue(r, 0, 6) }) } var Kn = .0010000000474974513; function Qn(o, t, e) { return yt.tidy(() => { let r = yt.depthwiseConv2d(o, t.filters, e, "same"); return r = yt.batchNorm(r, t.batch_norm_mean, t.batch_norm_variance, t.batch_norm_offset, t.batch_norm_scale, Kn), yt.clipByValue(r, 0, 6) }) } function ta(o) { return [2, 4, 6, 12].some(t => t === o) ? [2, 2] : [1, 1] } function zo(o, t) { return yt.tidy(() => { let e, r = q(o, t.conv_0, [2, 2]); if ([t.conv_1, t.conv_2, t.conv_3, t.conv_4, t.conv_5, t.conv_6, t.conv_7, t.conv_8, t.conv_9, t.conv_10, t.conv_11, t.conv_12, t.conv_13].forEach((a, s) => { let i = s + 1, c = ta(i); r = Qn(r, a.depthwise_conv, c), r = q(r, a.pointwise_conv, [1, 1]), i === 11 && (e = r) }), e === null) throw new Error("mobileNetV1 - output of conv layer 11 is null"); return { out: r, conv11: e } }) } function ea(o, t, e) { let r = o.arraySync(), n = Math.min(r[t][0], r[t][2]), a = Math.min(r[t][1], r[t][3]), s = Math.max(r[t][0], r[t][2]), i = Math.max(r[t][1], r[t][3]), c = Math.min(r[e][0], r[e][2]), m = Math.min(r[e][1], r[e][3]), p = Math.max(r[e][0], r[e][2]), d = Math.max(r[e][1], r[e][3]), u = (s - n) * (i - a), f = (p - c) * (d - m); if (u <= 0 || f <= 0) return 0; let v = Math.max(n, c), w = Math.max(a, m), h = Math.min(s, p), y = Math.min(i, d), T = Math.max(h - v, 0) * Math.max(y - w, 0); return T / (u + f - T) } function Vo(o, t, e, r, n) { let a = o.shape[0], s = Math.min(e, a), i = t.map((p, d) => ({ score: p, boxIndex: d })).filter(p => p.score > n).sort((p, d) => d.score - p.score), c = p => p <= r ? 1 : 0, m = []; return i.forEach(p => { if (m.length >= s) return; let d = p.score; for (let u = m.length - 1; u >= 0; --u) { let f = ea(o, p.boxIndex, m[u]); if (f !== 0 && (p.score *= c(f), p.score <= n)) break } d === p.score && m.push(p.boxIndex) }), m } var l = b(g()); function ra(o) { let t = l.unstack(l.transpose(o, [1, 0])), e = [l.sub(t[2], t[0]), l.sub(t[3], t[1])], r = [l.add(t[0], l.div(e[0], l.scalar(2))), l.add(t[1], l.div(e[1], l.scalar(2)))]; return { sizes: e, centers: r } } function oa(o, t) { let { sizes: e, centers: r } = ra(o), n = l.unstack(l.transpose(t, [1, 0])), a = l.div(l.mul(l.exp(l.div(n[2], l.scalar(5))), e[0]), l.scalar(2)), s = l.add(l.mul(l.div(n[0], l.scalar(10)), e[0]), r[0]), i = l.div(l.mul(l.exp(l.div(n[3], l.scalar(5))), e[1]), l.scalar(2)), c = l.add(l.mul(l.div(n[1], l.scalar(10)), e[1]), r[1]); return l.transpose(l.stack([l.sub(s, a), l.sub(c, i), l.add(s, a), l.add(c, i)]), [1, 0]) } function Uo(o, t, e) { return l.tidy(() => { let r = o.shape[0], n = oa(l.reshape(l.tile(e.extra_dim, [r, 1, 1]), [-1, 4]), l.reshape(o, [-1, 4])); n = l.reshape(n, [r, n.shape[0] / r, 4]); let a = l.sigmoid(l.slice(t, [0, 0, 1], [-1, -1, -1])), s = l.slice(a, [0, 0, 0], [-1, -1, 1]); s = l.reshape(s, [r, s.shape[1]]); let i = l.unstack(n), c = l.unstack(s); return { boxes: i, scores: c } }) } var $e = b(g()); var Oe = b(g()); function Ut(o, t) { return Oe.tidy(() => { let e = o.shape[0], r = Oe.reshape(zt(o, t.box_encoding_predictor), [e, -1, 1, 4]), n = Oe.reshape(zt(o, t.class_predictor), [e, -1, 3]); return { boxPredictionEncoding: r, classPrediction: n } }) } function Xo(o, t, e) { return $e.tidy(() => { let r = q(o, e.conv_0, [1, 1]), n = q(r, e.conv_1, [2, 2]), a = q(n, e.conv_2, [1, 1]), s = q(a, e.conv_3, [2, 2]), i = q(s, e.conv_4, [1, 1]), c = q(i, e.conv_5, [2, 2]), m = q(c, e.conv_6, [1, 1]), p = q(m, e.conv_7, [2, 2]), d = Ut(t, e.box_predictor_0), u = Ut(o, e.box_predictor_1), f = Ut(n, e.box_predictor_2), v = Ut(s, e.box_predictor_3), w = Ut(c, e.box_predictor_4), h = Ut(p, e.box_predictor_5), y = $e.concat([d.boxPredictionEncoding, u.boxPredictionEncoding, f.boxPredictionEncoding, v.boxPredictionEncoding, w.boxPredictionEncoding, h.boxPredictionEncoding], 1), T = $e.concat([d.classPrediction, u.classPrediction, f.classPrediction, v.classPrediction, w.classPrediction, h.classPrediction], 1); return { boxPredictions: y, classPredictions: T } }) } var Z = class { constructor({ minConfidence: t, maxResults: e } = {}) { this._name = "SsdMobilenetv1Options"; if (this._minConfidence = t || .5, this._maxResults = e || 100, typeof this._minConfidence != "number" || this._minConfidence <= 0 || this._minConfidence >= 1) throw new Error(`${this._name} - expected minConfidence to be a number between 0 and 1`); if (typeof this._maxResults != "number") throw new Error(`${this._name} - expected maxResults to be a number`) } get minConfidence() { return this._minConfidence } get maxResults() { return this._maxResults } }; var Xt = class extends S { constructor() { super("SsdMobilenetv1") } forwardInput(t) { let { params: e } = this; if (!e) throw new Error("SsdMobilenetv1 - load model before inference"); return st.tidy(() => { let r = st.cast(t.toBatchTensor(512, !1), "float32"), n = st.sub(st.mul(r, st.scalar(.007843137718737125)), st.scalar(1)), a = zo(n, e.mobilenetv1), { boxPredictions: s, classPredictions: i } = Xo(a.out, a.conv11, e.prediction_layer); return Uo(s, i, e.output_layer) }) } async forward(t) { return this.forwardInput(await E(t)) } async locateFaces(t, e = {}) { let { maxResults: r, minConfidence: n } = new Z(e), a = await E(t), { boxes: s, scores: i } = this.forwardInput(a), c = s[0], m = i[0]; for (let F = 1; F < s.length; F++)s[F].dispose(), i[F].dispose(); let p = Array.from(await m.data()), u = Vo(c, p, r, .5, n), f = a.getReshapedInputDimensions(0), v = a.inputSize, w = v / f.width, h = v / f.height, y = c.arraySync(), T = u.map(F => { let [L, G] = [Math.max(0, y[F][0]), Math.min(1, y[F][2])].map(X => X * h), [et, it] = [Math.max(0, y[F][1]), Math.min(1, y[F][3])].map(X => X * w); return new M(p[F], new oe(et, L, it - et, G - L), { height: a.getInputHeight(0), width: a.getInputWidth(0) }) }); return c.dispose(), m.dispose(), T } getDefaultModelName() { return "ssd_mobilenetv1_model" } extractParamsFromWeightMap(t) { return Go(t) } extractParams(t) { return Yo(t) } }; function Jo(o) { let t = new Xt; return t.extractWeights(o), t } function na(o) { return Jo(o) } var qo = class extends Xt { }; var Zo = .4, Ko = [new x(.738768, .874946), new x(2.42204, 2.65704), new x(4.30971, 7.04493), new x(10.246, 4.59428), new x(12.6868, 11.8741)], Qo = [new x(1.603231, 2.094468), new x(6.041143, 7.080126), new x(2.882459, 3.518061), new x(4.266906, 5.178857), new x(9.041765, 10.66308)], tn = [117.001, 114.697, 97.404], en = "tiny_yolov2_model", rn = "tiny_yolov2_separable_conv_model"; var N = b(g()); var br = o => typeof o == "number"; function io(o) { if (!o) throw new Error(`invalid config: ${o}`); if (typeof o.withSeparableConvs != "boolean") throw new Error(`config.withSeparableConvs has to be a boolean, have: ${o.withSeparableConvs}`); if (!br(o.iouThreshold) || o.iouThreshold < 0 || o.iouThreshold > 1) throw new Error(`config.iouThreshold has to be a number between [0, 1], have: ${o.iouThreshold}`); if (!Array.isArray(o.classes) || !o.classes.length || !o.classes.every(t => typeof t == "string")) throw new Error(`config.classes has to be an array class names: string[], have: ${JSON.stringify(o.classes)}`); if (!Array.isArray(o.anchors) || !o.anchors.length || !o.anchors.map(t => t || {}).every(t => br(t.x) && br(t.y))) throw new Error(`config.anchors has to be an array of { x: number, y: number }, have: ${JSON.stringify(o.anchors)}`); if (o.meanRgb && (!Array.isArray(o.meanRgb) || o.meanRgb.length !== 3 || !o.meanRgb.every(br))) throw new Error(`config.meanRgb has to be an array of shape [number, number, number], have: ${JSON.stringify(o.meanRgb)}`) } var Q = b(g()); var K = b(g()); function be(o) { return K.tidy(() => { let t = K.mul(o, K.scalar(.10000000149011612)); return K.add(K.relu(K.sub(o, t)), t) }) } function Ft(o, t) { return Q.tidy(() => { let e = Q.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]]); return e = Q.conv2d(e, t.conv.filters, [1, 1], "valid"), e = Q.sub(e, t.bn.sub), e = Q.mul(e, t.bn.truediv), e = Q.add(e, t.conv.bias), be(e) }) } var St = b(g()); function Tt(o, t) { return St.tidy(() => { let e = St.pad(o, [[0, 0], [1, 1], [1, 1], [0, 0]]); return e = St.separableConv2d(e, t.depthwise_filter, t.pointwise_filter, [1, 1], "valid"), e = St.add(e, t.bias), be(e) }) } var co = b(g()); function aa(o, t) { let e = ce(o, t); function r(s, i) { let c = co.tensor1d(o(s)), m = co.tensor1d(o(s)); return t.push({ paramPath: `${i}/sub` }, { paramPath: `${i}/truediv` }), { sub: c, truediv: m } } function n(s, i, c) { let m = e(s, i, 3, `${c}/conv`), p = r(i, `${c}/bn`); return { conv: m, bn: p } } let a = me(o, t); return { extractConvParams: e, extractConvWithBatchNormParams: n, extractSeparableConvParams: a } } function on(o, t, e, r) { let { extractWeights: n, getRemainingWeights: a } = B(o), s = [], { extractConvParams: i, extractConvWithBatchNormParams: c, extractSeparableConvParams: m } = aa(n, s), p; if (t.withSeparableConvs) { let [d, u, f, v, w, h, y, T, F] = r, L = t.isFirstLayerConv2d ? i(d, u, 3, "conv0") : m(d, u, "conv0"), G = m(u, f, "conv1"), et = m(f, v, "conv2"), it = m(v, w, "conv3"), X = m(w, h, "conv4"), Pt = m(h, y, "conv5"), wt = T ? m(y, T, "conv6") : void 0, _t = F ? m(T, F, "conv7") : void 0, te = i(F || T || y, 5 * e, 1, "conv8"); p = { conv0: L, conv1: G, conv2: et, conv3: it, conv4: X, conv5: Pt, conv6: wt, conv7: _t, conv8: te } } else { let [d, u, f, v, w, h, y, T, F] = r, L = c(d, u, "conv0"), G = c(u, f, "conv1"), et = c(f, v, "conv2"), it = c(v, w, "conv3"), X = c(w, h, "conv4"), Pt = c(h, y, "conv5"), wt = c(y, T, "conv6"), _t = c(T, F, "conv7"), te = i(F, 5 * e, 1, "conv8"); p = { conv0: L, conv1: G, conv2: et, conv3: it, conv4: X, conv5: Pt, conv6: wt, conv7: _t, conv8: te } } if (a().length !== 0) throw new Error(`weights remaing after extract: ${a().length}`); return { params: p, paramMappings: s } } function sa(o, t) { let e = j(o, t); function r(i) { let c = e(`${i}/sub`, 1), m = e(`${i}/truediv`, 1); return { sub: c, truediv: m } } function n(i) { let c = e(`${i}/filters`, 4), m = e(`${i}/bias`, 1); return { filters: c, bias: m } } function a(i) { let c = n(`${i}/conv`), m = r(`${i}/bn`); return { conv: c, bn: m } } let s = pe(e); return { extractConvParams: n, extractConvWithBatchNormParams: a, extractSeparableConvParams: s } } function nn(o, t) { let e = [], { extractConvParams: r, extractConvWithBatchNormParams: n, extractSeparableConvParams: a } = sa(o, e), s; if (t.withSeparableConvs) { let i = t.filterSizes && t.filterSizes.length || 9; s = { conv0: t.isFirstLayerConv2d ? r("conv0") : a("conv0"), conv1: a("conv1"), conv2: a("conv2"), conv3: a("conv3"), conv4: a("conv4"), conv5: a("conv5"), conv6: i > 7 ? a("conv6") : void 0, conv7: i > 8 ? a("conv7") : void 0, conv8: r("conv8") } } else s = { conv0: n("conv0"), conv1: n("conv1"), conv2: n("conv2"), conv3: n("conv3"), conv4: n("conv4"), conv5: n("conv5"), conv6: n("conv6"), conv7: n("conv7"), conv8: r("conv8") }; return W(o, e), { params: s, paramMappings: e } } var ft = class { constructor({ inputSize: t, scoreThreshold: e } = {}) { this._name = "TinyYolov2Options"; if (this._inputSize = t || 416, this._scoreThreshold = e || .5, typeof this._inputSize != "number" || this._inputSize % 32 != 0) throw new Error(`${this._name} - expected inputSize to be a number divisible by 32`); if (typeof this._scoreThreshold != "number" || this._scoreThreshold <= 0 || this._scoreThreshold >= 1) throw new Error(`${this._name} - expected scoreThreshold to be a number between 0 and 1`) } get inputSize() { return this._inputSize } get scoreThreshold() { return this._scoreThreshold } }; var mo = class extends S { constructor(t) { super("TinyYolov2"); io(t), this._config = t } get config() { return this._config } get withClassScores() { return this.config.withClassScores || this.config.classes.length > 1 } get boxEncodingSize() { return 5 + (this.withClassScores ? this.config.classes.length : 0) } runTinyYolov2(t, e) { let r = Ft(t, e.conv0); return r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Ft(r, e.conv1), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Ft(r, e.conv2), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Ft(r, e.conv3), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Ft(r, e.conv4), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Ft(r, e.conv5), r = N.maxPool(r, [2, 2], [1, 1], "same"), r = Ft(r, e.conv6), r = Ft(r, e.conv7), zt(r, e.conv8, "valid", !1) } runMobilenet(t, e) { let r = this.config.isFirstLayerConv2d ? be(zt(t, e.conv0, "valid", !1)) : Tt(t, e.conv0); return r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Tt(r, e.conv1), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Tt(r, e.conv2), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Tt(r, e.conv3), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Tt(r, e.conv4), r = N.maxPool(r, [2, 2], [2, 2], "same"), r = Tt(r, e.conv5), r = N.maxPool(r, [2, 2], [1, 1], "same"), r = e.conv6 ? Tt(r, e.conv6) : r, r = e.conv7 ? Tt(r, e.conv7) : r, zt(r, e.conv8, "valid", !1) } forwardInput(t, e) { let { params: r } = this; if (!r) throw new Error("TinyYolov2 - load model before inference"); return N.tidy(() => { let n = N.cast(t.toBatchTensor(e, !1), "float32"); return n = this.config.meanRgb ? ot(n, this.config.meanRgb) : n, n = n.div(N.scalar(256)), this.config.withSeparableConvs ? this.runMobilenet(n, r) : this.runTinyYolov2(n, r) }) } async forward(t, e) { return this.forwardInput(await E(t), e) } async detect(t, e = {}) { let { inputSize: r, scoreThreshold: n } = new ft(e), a = await E(t), s = await this.forwardInput(a, r), i = N.tidy(() => N.unstack(s)[0].expandDims()), c = { width: a.getInputWidth(0), height: a.getInputHeight(0) }, m = await this.extractBoxes(i, a.getReshapedInputDimensions(0), n); s.dispose(), i.dispose(); let p = m.map(h => h.box), d = m.map(h => h.score), u = m.map(h => h.classScore), f = m.map(h => this.config.classes[h.label]); return Wr(p.map(h => h.rescale(r)), d, this.config.iouThreshold, !0).map(h => new Dt(d[h], u[h], f[h], p[h], c)) } getDefaultModelName() { return "" } extractParamsFromWeightMap(t) { return nn(t, this.config) } extractParams(t) { let e = this.config.filterSizes || mo.DEFAULT_FILTER_SIZES, r = e ? e.length : void 0; if (r !== 7 && r !== 8 && r !== 9) throw new Error(`TinyYolov2 - expected 7 | 8 | 9 convolutional filters, but found ${r} filterSizes in config`); return on(t, this.config, this.boxEncodingSize, e) } async extractBoxes(t, e, r) { let { width: n, height: a } = e, s = Math.max(n, a), i = s / n, c = s / a, m = t.shape[1], p = this.config.anchors.length, [d, u, f] = N.tidy(() => { let y = t.reshape([m, m, p, this.boxEncodingSize]), T = y.slice([0, 0, 0, 0], [m, m, p, 4]), F = y.slice([0, 0, 0, 4], [m, m, p, 1]), L = this.withClassScores ? N.softmax(y.slice([0, 0, 0, 5], [m, m, p, this.config.classes.length]), 3) : N.scalar(0); return [T, F, L] }), v = [], w = await u.array(), h = await d.array(); for (let y = 0; y < m; y++)for (let T = 0; T < m; T++)for (let F = 0; F < p; F++) { let L = De(w[y][T][F][0]); if (!r || L > r) { let G = (T + De(h[y][T][F][0])) / m * i, et = (y + De(h[y][T][F][1])) / m * c, it = Math.exp(h[y][T][F][2]) * this.config.anchors[F].x / m * i, X = Math.exp(h[y][T][F][3]) * this.config.anchors[F].y / m * c, Pt = G - it / 2, wt = et - X / 2, _t = { row: y, col: T, anchor: F }, { classScore: te, label: ho } = this.withClassScores ? await this.extractPredictedClass(f, _t) : { classScore: 1, label: 0 }; v.push({ box: new re(Pt, wt, Pt + it, wt + X), score: L, classScore: L * te, label: ho, ..._t }) } } return d.dispose(), u.dispose(), f.dispose(), v } async extractPredictedClass(t, e) { let { row: r, col: n, anchor: a } = e, s = await t.array(); return Array(this.config.classes.length).fill(0).map((i, c) => s[r][n][a][c]).map((i, c) => ({ classScore: i, label: c })).reduce((i, c) => i.classScore > c.classScore ? i : c) } }, ge = mo; ge.DEFAULT_FILTER_SIZES = [3, 16, 32, 64, 128, 256, 512, 1024, 1024]; var ve = class extends ge { constructor(t = !0) { let e = { withSeparableConvs: t, iouThreshold: Zo, classes: ["face"], ...t ? { anchors: Qo, meanRgb: tn } : { anchors: Ko, withClassScores: !0 } }; super(e) } get withSeparableConvs() { return this.config.withSeparableConvs } get anchors() { return this.config.anchors } async locateFaces(t, e) { return (await this.detect(t, e)).map(n => new M(n.score, n.relativeBox, { width: n.imageWidth, height: n.imageHeight })) } getDefaultModelName() { return this.withSeparableConvs ? rn : en } extractParamsFromWeightMap(t) { return super.extractParamsFromWeightMap(t) } }; function ia(o, t = !0) { let e = new ve(t); return e.extractWeights(o), e } var gr = class extends ft { constructor() { super(...arguments); this._name = "TinyFaceDetectorOptions" } }; var tt = class { async then(t) { return t(await this.run()) } async run() { throw new Error("ComposableTask - run is not implemented") } }; var je = b(g()); var po = b(g()); async function Jt(o, t, e, r, n = ({ alignedRect: a }) => a) { let a = o.map(c => Vt(c) ? n(c) : c.detection), s = r || (t instanceof po.Tensor ? await se(t, a) : await ae(t, a)), i = await e(s); return s.forEach(c => c instanceof po.Tensor && c.dispose()), i } async function ye(o, t, e, r, n) { return Jt([o], t, async a => e(a[0]), r, n) } var an = .4, sn = [new x(1.603231, 2.094468), new x(6.041143, 7.080126), new x(2.882459, 3.518061), new x(4.266906, 5.178857), new x(9.041765, 10.66308)], cn = [117.001, 114.697, 97.404]; var Fe = class extends ge { constructor() { let t = { withSeparableConvs: !0, iouThreshold: an, classes: ["face"], anchors: sn, meanRgb: cn, isFirstLayerConv2d: !0, filterSizes: [3, 16, 32, 64, 128, 256, 512] }; super(t) } get anchors() { return this.config.anchors } async locateFaces(t, e) { return (await this.detect(t, e)).map(n => new M(n.score, n.relativeBox, { width: n.imageWidth, height: n.imageHeight })) } getDefaultModelName() { return "tiny_face_detector_model" } extractParamsFromWeightMap(t) { return super.extractParamsFromWeightMap(t) } }; var P = { ssdMobilenetv1: new Xt, tinyFaceDetector: new Fe, tinyYolov2: new ve, faceLandmark68Net: new le, faceLandmark68TinyNet: new dr, faceRecognitionNet: new xe, faceExpressionNet: new cr, ageGenderNet: new pr }, mn = (o, t) => P.ssdMobilenetv1.locateFaces(o, t), ca = (o, t) => P.tinyFaceDetector.locateFaces(o, t), ma = (o, t) => P.tinyYolov2.locateFaces(o, t), pn = o => P.faceLandmark68Net.detectLandmarks(o), pa = o => P.faceLandmark68TinyNet.detectLandmarks(o), da = o => P.faceRecognitionNet.computeFaceDescriptor(o), ua = o => P.faceExpressionNet.predictExpressions(o), fa = o => P.ageGenderNet.predictAgeAndGender(o), dn = o => P.ssdMobilenetv1.load(o), la = o => P.tinyFaceDetector.load(o), ha = o => P.tinyYolov2.load(o), xa = o => P.faceLandmark68Net.load(o), ba = o => P.faceLandmark68TinyNet.load(o), ga = o => P.faceRecognitionNet.load(o), va = o => P.faceExpressionNet.load(o), ya = o => P.ageGenderNet.load(o), Fa = dn, Ta = mn, Pa = pn; var uo = class extends tt { constructor(t, e, r) { super(); this.parentTask = t; this.input = e; this.extractedFaces = r } }, we = class extends uo { async run() { let t = await this.parentTask, e = await Jt(t, this.input, async r => Promise.all(r.map(n => P.faceExpressionNet.predictExpressions(n))), this.extractedFaces); return t.map((r, n) => mr(r, e[n])) } withAgeAndGender() { return new Te(this, this.input) } }, _e = class extends uo { async run() { let t = await this.parentTask; if (!t) return; let e = await ye(t, this.input, r => P.faceExpressionNet.predictExpressions(r), this.extractedFaces); return mr(t, e) } withAgeAndGender() { return new Pe(this, this.input) } }, Kt = class extends we { withAgeAndGender() { return new qt(this, this.input) } withFaceDescriptors() { return new At(this, this.input) } }, Qt = class extends _e { withAgeAndGender() { return new Zt(this, this.input) } withFaceDescriptor() { return new Wt(this, this.input) } }; var fo = class extends tt { constructor(t, e, r) { super(); this.parentTask = t; this.input = e; this.extractedFaces = r } }, Te = class extends fo { async run() { let t = await this.parentTask, e = await Jt(t, this.input, async r => Promise.all(r.map(n => P.ageGenderNet.predictAgeAndGender(n))), this.extractedFaces); return t.map((r, n) => { let { age: a, gender: s, genderProbability: i } = e[n]; return hr(xr(r, s, i), a) }) } withFaceExpressions() { return new we(this, this.input) } }, Pe = class extends fo { async run() { let t = await this.parentTask; if (!t) return; let { age: e, gender: r, genderProbability: n } = await ye(t, this.input, a => P.ageGenderNet.predictAgeAndGender(a), this.extractedFaces); return hr(xr(t, r, n), e) } withFaceExpressions() { return new _e(this, this.input) } }, qt = class extends Te { withFaceExpressions() { return new Kt(this, this.input) } withFaceDescriptors() { return new At(this, this.input) } }, Zt = class extends Pe { withFaceExpressions() { return new Qt(this, this.input) } withFaceDescriptor() { return new Wt(this, this.input) } }; var vr = class extends tt { constructor(t, e) { super(); this.parentTask = t; this.input = e } }, At = class extends vr { async run() { let t = await this.parentTask; return (await Jt(t, this.input, r => Promise.all(r.map(n => P.faceRecognitionNet.computeFaceDescriptor(n))), null, r => r.landmarks.align(null, { useDlibAlignment: !0 }))).map((r, n) => lr(t[n], r)) } withFaceExpressions() { return new Kt(this, this.input) } withAgeAndGender() { return new qt(this, this.input) } }, Wt = class extends vr { async run() { let t = await this.parentTask; if (!t) return; let e = await ye(t, this.input, r => P.faceRecognitionNet.computeFaceDescriptor(r), null, r => r.landmarks.align(null, { useDlibAlignment: !0 })); return lr(t, e) } withFaceExpressions() { return new Qt(this, this.input) } withAgeAndGender() { return new Zt(this, this.input) } }; var yr = class extends tt { constructor(t, e, r) { super(); this.parentTask = t; this.input = e; this.useTinyLandmarkNet = r } get landmarkNet() { return this.useTinyLandmarkNet ? P.faceLandmark68TinyNet : P.faceLandmark68Net } }, Fr = class extends yr { async run() { let t = await this.parentTask, e = t.map(a => a.detection), r = this.input instanceof je.Tensor ? await se(this.input, e) : await ae(this.input, e), n = await Promise.all(r.map(a => this.landmarkNet.detectLandmarks(a))); return r.forEach(a => a instanceof je.Tensor && a.dispose()), t.map((a, s) => fe(a, n[s])) } withFaceExpressions() { return new Kt(this, this.input) } withAgeAndGender() { return new qt(this, this.input) } withFaceDescriptors() { return new At(this, this.input) } }, Tr = class extends yr { async run() { let t = await this.parentTask; if (!t) return; let { detection: e } = t, r = this.input instanceof je.Tensor ? await se(this.input, [e]) : await ae(this.input, [e]), n = await this.landmarkNet.detectLandmarks(r[0]); return r.forEach(a => a instanceof je.Tensor && a.dispose()), fe(t, n) } withFaceExpressions() { return new Qt(this, this.input) } withAgeAndGender() { return new Zt(this, this.input) } withFaceDescriptor() { return new Wt(this, this.input) } }; var Pr = class extends tt { constructor(t, e = new Z) { super(); this.input = t; this.options = e } }, He = class extends Pr { async run() { let { input: t, options: e } = this, r = e instanceof gr ? n => P.tinyFaceDetector.locateFaces(n, e) : e instanceof Z ? n => P.ssdMobilenetv1.locateFaces(n, e) : e instanceof ft ? n => P.tinyYolov2.locateFaces(n, e) : null; if (!r) throw new Error("detectFaces - expected options to be instance of TinyFaceDetectorOptions | SsdMobilenetv1Options | MtcnnOptions | TinyYolov2Options"); return r(t) } runAndExtendWithFaceDetections() { return new Promise(async t => { let e = await this.run(); t(e.map(r => $t({}, r))) }) } withFaceLandmarks(t = !1) { return new Fr(this.runAndExtendWithFaceDetections(), this.input, t) } withFaceExpressions() { return new we(this.runAndExtendWithFaceDetections(), this.input) } withAgeAndGender() { return new Te(this.runAndExtendWithFaceDetections(), this.input) } }, wr = class extends Pr { async run() { let t = await new He(this.input, this.options), e = t[0]; return t.forEach(r => { r.score > e.score && (e = r) }), e } runAndExtendWithFaceDetection() { return new Promise(async t => { let e = await this.run(); t(e ? $t({}, e) : void 0) }) } withFaceLandmarks(t = !1) { return new Tr(this.runAndExtendWithFaceDetection(), this.input, t) } withFaceExpressions() { return new _e(this.runAndExtendWithFaceDetection(), this.input) } withAgeAndGender() { return new Pe(this.runAndExtendWithFaceDetection(), this.input) } }; function wa(o, t = new Z) { return new wr(o, t) } function _r(o, t = new Z) { return new He(o, t) } async function un(o, t) { return _r(o, new Z(t ? { minConfidence: t } : {})).withFaceLandmarks().withFaceDescriptors() } async function _a(o, t = {}) { return _r(o, new ft(t)).withFaceLandmarks().withFaceDescriptors() } var Da = un; function lo(o, t) { if (o.length !== t.length) throw new Error("euclideanDistance: arr1.length !== arr2.length"); let e = Array.from(o), r = Array.from(t); return Math.sqrt(e.map((n, a) => n - r[a]).reduce((n, a) => n + a ** 2, 0)) } var Dr = class { constructor(t, e = .6) { this._distanceThreshold = e; let r = Array.isArray(t) ? t : [t]; if (!r.length) throw new Error("FaceRecognizer.constructor - expected atleast one input"); let n = 1, a = () => `person ${n++}`; this._labeledDescriptors = r.map(s => { if (s instanceof xt) return s; if (s instanceof Float32Array) return new xt(a(), [s]); if (s.descriptor && s.descriptor instanceof Float32Array) return new xt(a(), [s.descriptor]); throw new Error("FaceRecognizer.constructor - expected inputs to be of type LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array | Array<LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array>") }) } get labeledDescriptors() { return this._labeledDescriptors } get distanceThreshold() { return this._distanceThreshold } computeMeanDistance(t, e) { return e.map(r => lo(r, t)).reduce((r, n) => r + n, 0) / (e.length || 1) } matchDescriptor(t) { return this.labeledDescriptors.map(({ descriptors: e, label: r }) => new Ee(r, this.computeMeanDistance(t, e))).reduce((e, r) => e.distance < r.distance ? e : r) } findBestMatch(t) { let e = this.matchDescriptor(t); return e.distance < this.distanceThreshold ? e : new Ee("unknown", e.distance) } toJSON() { return { distanceThreshold: this.distanceThreshold, labeledDescriptors: this.labeledDescriptors.map(t => t.toJSON()) } } static fromJSON(t) { let e = t.labeledDescriptors.map(r => xt.fromJSON(r)); return new Dr(e, t.distanceThreshold) } }; function Ea(o) { let t = new Fe; return t.extractWeights(o), t } function fn(o, t) { let { width: e, height: r } = new A(t.width, t.height); if (e <= 0 || r <= 0) throw new Error(`resizeResults - invalid dimensions: ${JSON.stringify({ width: e, height: r })}`); if (Array.isArray(o)) return o.map(n => fn(n, { width: e, height: r })); if (Vt(o)) { let n = o.detection.forSize(e, r), a = o.unshiftedLandmarks.forSize(n.box.width, n.box.height); return fe($t(o, n), a) } return pt(o) ? $t(o, o.detection.forSize(e, r)) : o instanceof V || o instanceof M ? o.forSize(e, r) : o } var Ca = typeof process != "undefined", Na = typeof navigator != "undefined" && typeof navigator.userAgent != "undefined", Ia = { faceapi: No, node: Ca, browser: Na };
//# sourceMappingURL=face-api.node.js.map
